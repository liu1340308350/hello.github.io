<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hadoop运行环境搭建</title>
    <url>/2020/03/27/Hadoop%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<h3 id="电脑配置要求："><a href="#电脑配置要求：" class="headerlink" title="电脑配置要求："></a>电脑配置要求：</h3><p>内存：最低8G，最好16G以上<br>硬盘：预留100G，实际上不妨数据大概不会超过20G</p>
<a id="more"></a>
<h3 id="系统环境："><a href="#系统环境：" class="headerlink" title="系统环境："></a>系统环境：</h3><p>Windows环境：Windows10<br>Linux环境：CentOS-6.10-x86_64-bin-DVD1<br>VMware：15.5.0 build-14665864</p>
<h3 id="所需文件"><a href="#所需文件" class="headerlink" title="所需文件"></a>所需文件</h3><p><strong>链接：</strong> <a href="https://pan.baidu.com/s/1X3Nfv5hBuJl6mGDNNcvnQA" target="_blank" rel="noopener">https://pan.baidu.com/s/1X3Nfv5hBuJl6mGDNNcvnQA</a><br>提取码：dgmt<br><strong>资源失效记得留言</strong></p>
<h3 id="检查是否开启虚拟机"><a href="#检查是否开启虚拟机" class="headerlink" title="检查是否开启虚拟机"></a>检查是否开启虚拟机</h3><p><img src="https://img-blog.csdnimg.cn/2020032710260212.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<h3 id="安装Linux"><a href="#安装Linux" class="headerlink" title="安装Linux"></a>安装Linux</h3><p>1.选择自定义<br><img src="https://img-blog.csdnimg.cn/20200327103653439.png?x-oss-process=image" alt="在这里插入图片描述"><br>2.下一步<br><img src="https://img-blog.csdnimg.cn/2020032710440027.png?x-oss-process=image" alt="在这里插入图片描述"><br>3.稍后安装操作系统<br><img src="https://img-blog.csdnimg.cn/20200327104418203.png?x-oss-process=image" alt="在这里插入图片描述"><br>4.选择Linux 版本为Centos6 64位<br><img src="https://img-blog.csdnimg.cn/20200327104437670.png?x-oss-process=image" alt="在这里插入图片描述"><br>5.虚拟机命名为Hadoop001<br><img src="https://img-blog.csdnimg.cn/20200327104457220.png?x-oss-process=image" alt="在这里插入图片描述"><br>6.处理机配置，这里配置最好对应下图：<br><img src="https://img-blog.csdnimg.cn/2020032710451572.png?x-oss-process=image" alt="在这里插入图片描述"><br><strong>注意:</strong> 如果电脑配置不足，虚拟机会自动提示，这里根据自己电脑配置调整即可<br><img src="https://img-blog.csdnimg.cn/20200327110559495.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<p>7.网络类型选择NAT<br><img src="https://img-blog.csdnimg.cn/20200327104532614.png?x-oss-process=image" alt="在这里插入图片描述"><br>8.I/O控制器类型选择LSI Logic<br><img src="https://img-blog.csdnimg.cn/20200327104555764.png?x-oss-process=image" alt="在这里插入图片描述"><br>9.磁盘类型选择SCSI<br><img src="https://img-blog.csdnimg.cn/20200327104618841.png?x-oss-process=image" alt="在这里插入图片描述"><br>10.创建新虚拟磁盘<br><img src="https://img-blog.csdnimg.cn/20200327104635294.png?x-oss-process=image" alt="在这里插入图片描述"><br>11.磁盘大小分配50G，将虚拟磁盘拆分成多个文件<br><img src="https://img-blog.csdnimg.cn/20200327104652738.png?x-oss-process=image" alt="在这里插入图片描述"><br>12.指定磁盘文件<br><img src="https://img-blog.csdnimg.cn/20200327104707478.png?x-oss-process=image" alt="在这里插入图片描述"><br>13.创建完成<br><img src="https://img-blog.csdnimg.cn/2020032710473853.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<p>14.在虚拟机配置中选择下载好的镜像文件<br><img src="https://img-blog.csdnimg.cn/20200327104750966.png?x-oss-process=image" alt="在这里插入图片描述"><br>15.选择第一个<br> <img src="https://img-blog.csdnimg.cn/20200327105929634.png?x-oss-process=image" alt="在这里插入图片描述"><br>16.选择skip<br><img src="https://img-blog.csdnimg.cn/20200327105959950.png?x-oss-process=image" alt="在这里插入图片描述"><br>17.选择next<br><img src="https://img-blog.csdnimg.cn/20200327110029718.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<p>18.语言环境选择英文<br><img src="https://img-blog.csdnimg.cn/20200327110101712.png?x-oss-process=image" alt="在这里插入图片描述"><br>19.选择输入法<br><img src="https://img-blog.csdnimg.cn/20200327110230645.png?x-oss-process=image" alt="在这里插入图片描述"><br>20.选择Basic Storage Devices<br><img src="https://img-blog.csdnimg.cn/20200327110259402.png?x-oss-process=image" alt="在这里插入图片描述"><br>21.同意即可<br><img src="https://img-blog.csdnimg.cn/20200327110344102.png?x-oss-process=image" alt="在这里插入图片描述"><br>22.主机命名<br><img src="https://img-blog.csdnimg.cn/20200327110434306.png?x-oss-process=image" alt="在这里插入图片描述"><br>23.配置Configure Network<br><img src="https://img-blog.csdnimg.cn/20200327110518430.png?x-oss-process=image" alt="在这里插入图片描述"><br>24.勾选即可<br><img src="https://img-blog.csdnimg.cn/20200327110749262.png?x-oss-process=image" alt="在这里插入图片描述"><br>25.选择相应的时区<br><img src="https://img-blog.csdnimg.cn/20200327110908993.png?x-oss-process=image" alt="在这里插入图片描述"><br>26.密码设个123456就行了<br><img src="https://img-blog.csdnimg.cn/20200327110937171.png?x-oss-process=image" alt="在这里插入图片描述"><br>27.选择Use All Space<br><img src="https://img-blog.csdnimg.cn/20200327111016724.png?x-oss-process=image0" alt="在这里插入图片描述"><br>28.write changes to disk<br><img src="https://img-blog.csdnimg.cn/20200327111055987.png?x-oss-process=image" alt="在这里插入图片描述"><br>29.选择Basic<br><img src="https://img-blog.csdnimg.cn/20200327111132984.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<p>30.系统开始初始化<br><img src="https://img-blog.csdnimg.cn/20200327111233395.png?x-oss-process=image" alt="在这里插入图片描述"><br>31.可见系统已经安装成功，reboot重启即可<img src="https://img-blog.csdnimg.cn/20200327111308432.png?x-oss-process=image" alt="在这里插入图片描述"><br>32.进入系统界面<br><img src="https://img-blog.csdnimg.cn/20200327111408414.png?x-oss-process=image" alt="在这里插入图片描述"><br>因为hadoop实验需要3个服务器，另外两个可以使用克隆安装<br>33.选择下一步<img src="https://img-blog.csdnimg.cn/20200327111548739.png?x-oss-process=image" alt="在这里插入图片描述"><br>34.下一步<br><img src="https://img-blog.csdnimg.cn/20200327111614282.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<p>35.克隆类型选择链接克隆，尽量节省磁盘空间<br><img src="https://img-blog.csdnimg.cn/2020032711163713.png?x-oss-process=image" alt="在这里插入图片描述"><br>36.命名<br><img src="https://img-blog.csdnimg.cn/20200327111730702.png?x-oss-process=image" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200327111810391.png?x-oss-process=image" alt="在这里插入图片描述"><br>37.可以看到安装完成之后的情形<br><img src="https://img-blog.csdnimg.cn/20200327111851452.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200327111909745.png" alt="在这里插入图片描述"></p>
<h3 id="网络配置"><a href="#网络配置" class="headerlink" title="网络配置"></a>网络配置</h3><h4 id="1-配置网卡"><a href="#1-配置网卡" class="headerlink" title="1.配置网卡"></a>1.配置网卡</h4><p><img src="https://img-blog.csdnimg.cn/20200327112637566.png" alt="在这里插入图片描述"><br>输入上面的命令可以查看hadoop01的网络环境：如下图所示<br><img src="https://img-blog.csdnimg.cn/20200327112644781.png" alt="在这里插入图片描述"><br>然后开始修改hadoop02，hadoop03的网络配置<br><img src="https://img-blog.csdnimg.cn/20200327112715134.png?x-oss-process=image" alt="在这里插入图片描述"><br>改动如下图所示：<br>也就是将上面的配置删除，下面的NAME=”eth1” 改成eth0<br><img src="https://img-blog.csdnimg.cn/20200327112733595.png" alt="在这里插入图片描述"><br>hadoop03的操作和hadoop02的一样</p>
<p><strong>注意：</strong> 这里的MAC地址不能一样，如果一样，就需要自动生成一个<br><img src="https://img-blog.csdnimg.cn/20200327113128393.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<h4 id="2-配置静态ip"><a href="#2-配置静态ip" class="headerlink" title="2.配置静态ip"></a>2.配置静态ip</h4><p>修改hadoop01，02，03的网络配置文件(ifcfg-eth0)<br><img src="https://img-blog.csdnimg.cn/20200327113449436.png" alt="在这里插入图片描述"><br>可以查看配置文件的内容如下图所示：<br><img src="https://img-blog.csdnimg.cn/20200327113458775.png" alt="在这里插入图片描述"><br>将网络配置改为下面的：<br><img src="https://img-blog.csdnimg.cn/20200327113507394.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<p>验证网络配置：<br><img src="https://img-blog.csdnimg.cn/20200327113527171.png?x-oss-process=image" alt="在这里插入图片描述"><br>这里使用静态IP，ip地址分别是134 135 136<br>hadoop02和hadoop03的操作和hadoop01的一样，重复即可</p>
<h4 id="3-配置虚拟机网络"><a href="#3-配置虚拟机网络" class="headerlink" title="3.配置虚拟机网络"></a>3.配置虚拟机网络</h4><p>首先需要检查是否开启了5个服务<br>在控制面板的服务里面可以看到是否开启<br><img src="https://img-blog.csdnimg.cn/20200327112000348.png" alt="在这里插入图片描述"><br>1.编辑-&gt;虚拟网络编辑器<br><img src="https://img-blog.csdnimg.cn/20200327114410335.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpdTEzNDAzMDgzNTA=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>2.配置网络编辑器<br><img src="https://img-blog.csdnimg.cn/20200327114500515.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/20200327114550386.png?x-oss-process=image" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200327114917915.png?x-oss-process=image" alt="在这里插入图片描述"><br>NAT设置如图所示：<br><img src="https://img-blog.csdnimg.cn/20200327114628469.png?x-oss-process=image" alt="在这里插入图片描述"><br>DHCP设置如图所示：<br><img src="https://img-blog.csdnimg.cn/2020032711470347.png?x-oss-process=image" alt="在这里插入图片描述"><br>修改VMware network<br><img src="https://img-blog.csdnimg.cn/20200327114710335.png" alt="在这里插入图片描述"><br>将VMnet8的ipv4修改为下图所示<br><img src="https://img-blog.csdnimg.cn/20200327114717792.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<h4 id="4-主机名映射配置"><a href="#4-主机名映射配置" class="headerlink" title="4.主机名映射配置"></a>4.主机名映射配置</h4><p><img src="https://img-blog.csdnimg.cn/20200327115555637.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200327115608830.png" alt="在这里插入图片描述"></p>
<h4 id="5-IP映射配置"><a href="#5-IP映射配置" class="headerlink" title="5.IP映射配置"></a>5.IP映射配置</h4><p><img src="https://img-blog.csdnimg.cn/20200327115618260.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200327115627958.png" alt="在这里插入图片描述"></p>
<h4 id="6-windows的hosts配置"><a href="#6-windows的hosts配置" class="headerlink" title="6.windows的hosts配置"></a>6.windows的hosts配置</h4><p>修改Windows下的hosts文件<br><img src="https://img-blog.csdnimg.cn/20200327115930695.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200327115937887.png" alt="在这里插入图片描述"></p>
<p><strong>注意：</strong>网络配置完成记得重启网络服务<br><code>service network restart</code>或者重启服务器<code>reboot</code><br>完成以上步骤，网络配置就算完成</p>
<h4 id="7-测试网络配置"><a href="#7-测试网络配置" class="headerlink" title="7.测试网络配置"></a>7.测试网络配置</h4><p>接下来测试网络配置是否完成<br><img src="https://img-blog.csdnimg.cn/20200327120013734.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<blockquote>
<p>ifcfg-eth0 配置参数说明<br>1.TYPE：配置文件接口类型。在/etc/sysconfig/network-scripts/目录有多种网络配置文件，有Ethernet 、IPsec等类型，网络接口类型为Ethernet。<br>2.DEVICE：网络接口名称<br>3.BOOTPROTO：系统启动地址协议<br>4.none：不使用启动地址协议<br>5.bootp：BOOTP协议<br>6.dhcp：DHCP动态地址协议<br>7.static：静态地址协议<br>8.ONBOOT：系统启动时是否激活<br>            yes：系统启动时激活该网络接口<br>            no：系统启动时不激活该网络接口<br>9.IPADDR：IP地址<br>10.NETMASK：子网掩码<br>11.GATEWAY：网关地址<br>12.BROADCAST：广播地址<br>13.HWADDR/MACADDR：MAC地址。只需设置其中一个，同时设置时不能相互冲突。<br>14.PEERDNS：是否指定DNS。如果使用DHCP协议，默认为yes</p>
</blockquote>
<h3 id="SSH配置"><a href="#SSH配置" class="headerlink" title="SSH配置"></a>SSH配置</h3><p>输入<code>rpm -qa|grep ssh</code>查看ssh是否安装<br><img src="https://img-blog.csdnimg.cn/20200327121043104.png" alt="在这里插入图片描述"><br>如果没有安装：<code>yum install openssh-server</code></p>
<h3 id="免密登陆"><a href="#免密登陆" class="headerlink" title="免密登陆"></a>免密登陆</h3><p>1.为什么要免密登录<br>Hadoop节点众多，所以一般在主节点启动从节点，这个时候就需要程序自动在主节点登录<br>到从节点中，如果不能免密就每次都要输入密码，非常麻烦<br>2. 免密SSH登录的原理<br>需要先在B节点配置A节点的公钥<br>A节点请求B节点要球登录<br>B节点使用A节点的公钥，加密一段随机文本<br>A节点使用私钥解密，并发回给B节点<br>B节点验证文本是否正确</p>
<p><img src="https://img-blog.csdnimg.cn/20200327121318858.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<p>这里为了更方便的操作，使用secureCRT文件<br>打开secureCRT文件，new Session创建相应的session连接<br>1.new Session<img src="https://img-blog.csdnimg.cn/20200327122809177.png" alt="在这里插入图片描述"><br>2.下一步<br><img src="https://img-blog.csdnimg.cn/20200327122947738.png?x-oss-process=image" alt="在这里插入图片描述"><br>3.填写相应信息<br><img src="https://img-blog.csdnimg.cn/20200327123020515.png?x-oss-process=image" alt="在这里插入图片描述"><br>4.SFTP协议<img src="https://img-blog.csdnimg.cn/20200327123105814.png?x-oss-process=image" alt="在这里插入图片描述"><br>5.命名<br><img src="https://img-blog.csdnimg.cn/2020032712314534.png?x-oss-process=image" alt="在这里插入图片描述"><br>最后效果：<br> <img src="https://img-blog.csdnimg.cn/20200327123215433.png" alt="在这里插入图片描述"><br> 配置完成之后虚拟机就可以后台运行了<br><img src="https://img-blog.csdnimg.cn/20200327124339234.png?x-oss-process=image" alt="在这里插入图片描述"><br>这里为了软件的美观，可以进行相应的设置<br>这里推荐一个配色方案：<br><a href="https://blog.51cto.com/sandshell/2109176" target="_blank" rel="noopener">SecureCRT优化调整、永久设置、保护眼睛和配色方案</a></p>
<h4 id="配置免密登录"><a href="#配置免密登录" class="headerlink" title="配置免密登录"></a>配置免密登录</h4><p>1.在三台机器执行以下命令，生成公钥与私钥<br><code>ssh-keygen -t rsa</code><br>一直回车就行了<br><img src="https://img-blog.csdnimg.cn/20200327123828820.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<p>2.复制<code>ssh-copy-id hadoop01</code><br><img src="https://img-blog.csdnimg.cn/20200327123939763.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200327123952454.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200327124005151.png?x-oss-process=image" alt="在这里插入图片描述"><br>将第一台机器的公钥拷贝到其他机器<br><code>scp /root/.ssh/authorized_keys hadoop02:/root/.ssh</code><br><code>scp /root/.ssh/authorized_keys hadoop03:/root/.ssh</code><br><img src="https://img-blog.csdnimg.cn/20200327124148240.png" alt="在这里插入图片描述"><br>如果3台机器可以相互访问，说明配置成功<br><img src="https://img-blog.csdnimg.cn/20200327124153657.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<h3 id="hadoop安装"><a href="#hadoop安装" class="headerlink" title="hadoop安装"></a>hadoop安装</h3><blockquote>
<p>Hadoop集群部署模式 </p>
<ol>
<li>在独立模式下，所有程序都在单个VM上执行，调试Hadoop集群的MapReduce程序也非常方便。一般情况下，该模式常用于学习或开发阶段进行调试程序。</li>
<li>在伪分布式模式下，Hadoop程序的守护进程都运行在一台节点上，该模式主要用于调试Hadoop分布式程序的代码，以及程序执行是否正确。伪分布式模式是完全分布式模式的一个特例。</li>
<li>在完全分布式模式下，Hadoop的守护进程分别运行在由多个主机措建的集群上，不同节点担任不同的角色，在实际工作应用开发中，通常使用该模式构建企业级Hadoop系统。</li>
</ol>
</blockquote>
<blockquote>
<p>从JDK版本7u71以后，JAVA将会在同一时间发布两个版本的JDK，其中： </p>
<ol>
<li>奇数版本为BUG修正并全部通过检验的版本，官方强烈推荐使用这个版本。</li>
<li>偶数版本包含了奇数版本所有的内容，以及未被验证的BUG修复，Oracle官方表示：除非你深受BUG困扰，否则不推荐您使用这个版本。</li>
</ol>
</blockquote>
<p><a href="http://hbase.apache.org/book.html#basic.prerequisites" target="_blank" rel="noopener">http://hbase.apache.org/book.html#basic.prerequisites</a><br><a href="http://hive.apache.org/downloads.html" target="_blank" rel="noopener">http://hive.apache.org/downloads.html</a><br><a href="https://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank" rel="noopener">https://www.oracle.com/technetwork/java/javase/downloads/index.html</a><br>根据官网推荐，使用如下软件配置<br><img src="https://img-blog.csdnimg.cn/202003271247571.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<h4 id="1-上传文件并创建相应文件"><a href="#1-上传文件并创建相应文件" class="headerlink" title="1.上传文件并创建相应文件"></a>1.上传文件并创建相应文件</h4><p>1.创建文件：在根目录下创建下图文件<br><img src="https://img-blog.csdnimg.cn/2020032712490655.png" alt="在这里插入图片描述"></p>
<p>2.通过命令将文件拖进software文件中<br>安装上传文件命令<code>yum install -y lrzsz</code><br>执行命令rz，上传文件<br>执行命令sz，下载文件<br><img src="https://img-blog.csdnimg.cn/20200327125021970.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<h4 id="2-安装JDK"><a href="#2-安装JDK" class="headerlink" title="2.安装JDK"></a>2.安装JDK</h4><p>解压jdk文件到/export/servers/路径下<br><code>tar -zxvf jdk-8u201-linux-x64.tar.gz -C /export/servers/</code><br>将jdk文件移动到jdk路径下<br><code>mv jdk1.8.0_201 jdk</code></p>
<p>4.添加环境变量<br><code>vim /etc/profile</code><br>添加下列代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME&#x3D;&#x2F;export&#x2F;servers&#x2F;jdk</span><br><span class="line">export PATH&#x3D;$JAVA_HOME&#x2F;bin:$PATH</span><br><span class="line">export CLASSPATH&#x3D;.:$JAVA_HOME&#x2F;lib&#x2F;dt.jar:$JAVA_HOME&#x2F;lib&#x2F;tools.jar</span><br></pre></td></tr></table></figure>
<p>添加完成之后记得<code>source /etc/profile</code>使配置生效<br>测试：<br><code>java -version</code><br><img src="https://img-blog.csdnimg.cn/20200327125713207.png" alt="在这里插入图片描述"><br><code>which java</code><br><img src="https://img-blog.csdnimg.cn/20200327125729409.png" alt="在这里插入图片描述"></p>
<h4 id="安装hadoop"><a href="#安装hadoop" class="headerlink" title="安装hadoop"></a>安装hadoop</h4><p>1.解压<br><code>tar -zxvf hadoop-2.7.7.tar.gz -C /export/servers/</code><br>2.编写<code>/etc/profile文件</code><br><code>vim /etc/profile</code><br>添加下列命令：<br><img src="https://img-blog.csdnimg.cn/20200327125936586.png" alt="在这里插入图片描述"><br>配置完成之后：<code>source /etc/profile</code><br> <img src="https://img-blog.csdnimg.cn/20200327125950742.png" alt="在这里插入图片描述"><br> 测试：<br> <code>hadoop version</code>查看是否配置完成<img src="https://img-blog.csdnimg.cn/2020032713000287.png" alt="在这里插入图片描述"></p>
<h3 id="hadoop入门案例："><a href="#hadoop入门案例：" class="headerlink" title="hadoop入门案例："></a>hadoop入门案例：</h3><p><img src="https://img-blog.csdnimg.cn/20200327130134643.png" alt="在这里插入图片描述"><br>1.进入hadoop-2.7.7下面<br>2.创建一个input文件夹<br>3.将Hadoop的xml配置文件复制到input<br>xml配置文件是etc/hadoop/*.xml’</p>
<p>4.执行share目录下的MapReduce程序<br><code>hadoop jar hadoop-mapreduce-examples-2.7.2.jar grep input output &#39;dfs[a-z.]+&#39;</code><br><img src="https://img-blog.csdnimg.cn/20200327130119673.png?x-oss-process=image" alt="在这里插入图片描述"><br>5.在<strong>hadoop-2.7.7路径下</strong>查看输出结果<br><code>cat output/*</code></p>
<p><strong>注意:</strong> hadoop jar 是命令，hadoop-mapreduce-examples-2.7.7.jar是自己写的mr代码，input 输入文件夹，output 输出文件夹</p>
]]></content>
      <categories>
        <category>Hadoop集群</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Java多线程</title>
    <url>/2020/08/04/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B/</url>
    <content><![CDATA[<h3 id="一-基本概念：程序、进程、线程"><a href="#一-基本概念：程序、进程、线程" class="headerlink" title="一.基本概念：程序、进程、线程"></a>一.基本概念：程序、进程、线程</h3><p>程序(program)是为完成特定任务、用某种语言编写的一组指令的集合。即指一段静态的代码，静态对象。<br>进程(process)是程序的一次执行过程，或是正在运行的一个程序。是一个动态的过程：有它自身的产生、存在和消亡的过程。也就是生命周期</p>
<blockquote>
<p>如：运行的QQ，运行中的MP3播放器<br>程序是静态的，进程是动态的<br>进程作为资源分配的单位，系统在运行时会为每个进程不同的内存区域。</p>
</blockquote>
<p>线程(thread)：进程可以进一步细化为线程，是一个程序内部的一条执行路径。</p>
<blockquote>
<p>若一个进程同一时间并行执行多个线程，就是支持多线程的。<br>线程作为调度和执行的单位，每个线程拥有独立的运行栈和程序计数器(PC)，线程切换的开销小<br>一个进程中的多个线程共享相同的内存单元/内存地址空间-&gt;它们从同一堆中分配对象，可以访问相同的变量和对象。这就使得线程间通信更简便、高效。但多个线程操作共享的系统资源可能带来安全的隐患。</p>
</blockquote>
<p><strong>单核CPU与多核CPU的理解</strong></p>
<p>单核CPU，其实是一种假的多线程，因为在一个时间单元内，也只能执行一个线程的任务。例如：虽然有多车道，但是收费站只有一个工作人员在收费，只有收了费才能通过，那么CPU就好比收费人员。如果有某个人不想交钱，那么收费人员可以把他“挂起”。但是因为CPU时间单元特别短，所以感觉不出来。</p>
<p>多核CPU</p>
<p><strong>并发与并行</strong></p>
<p>并行：多个CPU同时执行多个任务。例如：多个人同时做不同的事情。</p>
<p>并发：一个CPU（采用时间片）同时执行多个任务。例如：秒杀，多个人做一件事。</p>
<p><strong>多线程的优点</strong></p>
<p>1.提高应用程序的响应。对图形化界面更有意义，可以增强用户体验。</p>
<p>2.提高计算机系统CPU的利用率</p>
<p>3.改善程序结构。将既长又复杂的进程分为多个线程，独立运行，利于理解和修改</p>
<h3 id="二-线程的创建和使用"><a href="#二-线程的创建和使用" class="headerlink" title="二.线程的创建和使用"></a>二.线程的创建和使用</h3><p>多线程的创建，方式一：继承与Thread类</p>
<p>1.创建一个类继承于Thread类的子类</p>
<p>2.重写Thread类的run()  ——》将此线程执行的操作声明在run()中</p>
<p>3.创建Thread类的子类的对象</p>
<p>4.通过此对象调用start()</p>
<p><strong>线程的调度</strong>：</p>
<h3 id="三-线程的生命周期"><a href="#三-线程的生命周期" class="headerlink" title="三.线程的生命周期"></a>三.线程的生命周期</h3><h1 id="线程的状态变化"><a href="#线程的状态变化" class="headerlink" title="线程的状态变化"></a>线程的状态变化</h1><p>要想实现多线程，必须在主线程中创建新的线程对象。任何线程一般具有5种状态，即创建，就绪，运行，阻塞，终止。下面分别介绍一下这几种状态：</p>
<ul>
<li>创建状态 </li>
</ul>
<p>在程序中用构造方法创建了一个线程对象后，新的线程对象便处于新建状态，此时它已经有了相应的内存空间和其他资源，但还处于不可运行状态。新建一个线程对象可采用Thread 类的构造方法来实现，例如 “Thread thread=new Thread()”。</p>
<ul>
<li>就绪状态 </li>
</ul>
<p>新建线程对象后，调用该线程的 start() 方法就可以启动线程。当线程启动时，线程进入就绪状态。此时，线程将进入线程队列排队，等待 CPU 服务，这表明它已经具备了运行条件。</p>
<ul>
<li>运行状态 </li>
</ul>
<p>当就绪状态被调用并获得处理器资源时，线程就进入了运行状态。此时，自动调用该线程对象的 run() 方法。run() 方法定义该线程的操作和功能。</p>
<ul>
<li>阻塞状态 </li>
</ul>
<p>一个正在执行的线程在某些特殊情况下，如被人为挂起或需要执行耗时的输入/输出操作，会让 CPU 暂时中止自己的执行，进入阻塞状态。在可执行状态下，如果调用sleep(),suspend(),wait() 等方法，线程都将进入阻塞状态，发生阻塞时线程不能进入排队队列，只有当引起阻塞的原因被消除后，线程才可以转入就绪状态。</p>
<ul>
<li>死亡状态 </li>
</ul>
<p>线程调用 stop() 方法时或 run() 方法执行结束后，即处于死亡状态。处于死亡状态的线程不具有继续运行的能力。</p>
<p>在此提出一个问题，Java 程序每次运行至少启动几个线程？</p>
<p>回答：至少启动两个线程，每当使用 Java 命令执行一个类时，实际上都会启动一个 JVM，每一个JVM实际上就是在操作系统中启动一个线程，Java 本身具备了垃圾的收集机制。所以在 Java 运行时至少会启动两个线程，一个是 main 线程，另外一个是垃圾收集线程。</p>
<h3 id="四-线程的同步"><a href="#四-线程的同步" class="headerlink" title="四.线程的同步"></a>四.线程的同步</h3><h3 id="五-线程的通信"><a href="#五-线程的通信" class="headerlink" title="五.线程的通信"></a>五.线程的通信</h3><h3 id="六-JDK5-0新增线程创建方式"><a href="#六-JDK5-0新增线程创建方式" class="headerlink" title="六.JDK5.0新增线程创建方式"></a>六.JDK5.0新增线程创建方式</h3>]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>多线程</tag>
        <tag>JavaSE</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop集群搭建</title>
    <url>/2020/03/28/Hadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<blockquote>
<p>Hadoop集群搭建之前记得完成hadoop运行环境的搭建</p>
</blockquote>
<a id="more"></a>
<p>hadoop集群搭建：<br><img src="https://img-blog.csdnimg.cn/20200327140632968.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<p>也就是要修改以下文件<br><img src="https://img-blog.csdnimg.cn/20200327140653262.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<h3 id="修改方法"><a href="#修改方法" class="headerlink" title="修改方法"></a>修改方法</h3><p>1.使用sublime文件<br>配置方法：<a href="https://blog.csdn.net/liu1340308350/article/details/105139669" target="_blank" rel="noopener">https://blog.csdn.net/liu1340308350/article/details/105139669</a><br>2.直接在secureCRT中配置<br>这里我是使用第一种方法配置的</p>
<h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><h4 id="hadoop-env-sh"><a href="#hadoop-env-sh" class="headerlink" title="hadoop-env.sh"></a>hadoop-env.sh</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Licensed to the Apache Software Foundation (ASF) under one</span></span><br><span class="line"><span class="comment"># or more contributor license agreements.  See the NOTICE file</span></span><br><span class="line"><span class="comment"># distributed with this work for additional information</span></span><br><span class="line"><span class="comment"># regarding copyright ownership.  The ASF licenses this file</span></span><br><span class="line"><span class="comment"># to you under the Apache License, Version 2.0 (the</span></span><br><span class="line"><span class="comment"># "License"); you may not use this file except in compliance</span></span><br><span class="line"><span class="comment"># with the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set Hadoop-specific environment variables here.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The only required environment variable is JAVA_HOME.  All others are</span></span><br><span class="line"><span class="comment"># optional.  When running a distributed configuration it is best to</span></span><br><span class="line"><span class="comment"># set JAVA_HOME in this file, so that it is correctly defined on</span></span><br><span class="line"><span class="comment"># remote nodes.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The java implementation to use.</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/<span class="built_in">export</span>/servers/jdk</span><br><span class="line"></span><br><span class="line"><span class="comment"># The jsvc implementation to use. Jsvc is required to run secure datanodes</span></span><br><span class="line"><span class="comment"># that bind to privileged ports to provide authentication of data transfer</span></span><br><span class="line"><span class="comment"># protocol.  Jsvc is not required if SASL is configured for authentication of</span></span><br><span class="line"><span class="comment"># data transfer protocol using non-privileged ports.</span></span><br><span class="line"><span class="comment">#export JSVC_HOME=$&#123;JSVC_HOME&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=<span class="variable">$&#123;HADOOP_CONF_DIR:-"/etc/hadoop"&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Extra Java CLASSPATH elements.  Automatically insert capacity-scheduler.</span></span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> <span class="variable">$HADOOP_HOME</span>/contrib/capacity-scheduler/*.jar; <span class="keyword">do</span></span><br><span class="line">  <span class="keyword">if</span> [ <span class="string">"<span class="variable">$HADOOP_CLASSPATH</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">export</span> HADOOP_CLASSPATH=<span class="variable">$HADOOP_CLASSPATH</span>:<span class="variable">$f</span></span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    <span class="built_in">export</span> HADOOP_CLASSPATH=<span class="variable">$f</span></span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The maximum amount of heap to use, in MB. Default is 1000.</span></span><br><span class="line"><span class="comment">#export HADOOP_HEAPSIZE=</span></span><br><span class="line"><span class="comment">#export HADOOP_NAMENODE_INIT_HEAPSIZE=""</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Extra Java runtime options.  Empty by default.</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_OPTS=<span class="string">"<span class="variable">$HADOOP_OPTS</span> -Djava.net.preferIPv4Stack=true"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Command specific options appended to HADOOP_OPTS when specified</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_NAMENODE_OPTS=<span class="string">"-Dhadoop.security.logger=<span class="variable">$&#123;HADOOP_SECURITY_LOGGER:-INFO,RFAS&#125;</span> -Dhdfs.audit.logger=<span class="variable">$&#123;HDFS_AUDIT_LOGGER:-INFO,NullAppender&#125;</span> <span class="variable">$HADOOP_NAMENODE_OPTS</span>"</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_DATANODE_OPTS=<span class="string">"-Dhadoop.security.logger=ERROR,RFAS <span class="variable">$HADOOP_DATANODE_OPTS</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HADOOP_SECONDARYNAMENODE_OPTS=<span class="string">"-Dhadoop.security.logger=<span class="variable">$&#123;HADOOP_SECURITY_LOGGER:-INFO,RFAS&#125;</span> -Dhdfs.audit.logger=<span class="variable">$&#123;HDFS_AUDIT_LOGGER:-INFO,NullAppender&#125;</span> <span class="variable">$HADOOP_SECONDARYNAMENODE_OPTS</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HADOOP_NFS3_OPTS=<span class="string">"<span class="variable">$HADOOP_NFS3_OPTS</span>"</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_PORTMAP_OPTS=<span class="string">"-Xmx512m <span class="variable">$HADOOP_PORTMAP_OPTS</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The following applies to multiple commands (fs, dfs, fsck, distcp etc)</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_CLIENT_OPTS=<span class="string">"-Xmx512m <span class="variable">$HADOOP_CLIENT_OPTS</span>"</span></span><br><span class="line"><span class="comment">#HADOOP_JAVA_PLATFORM_OPTS="-XX:-UsePerfData $HADOOP_JAVA_PLATFORM_OPTS"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># On secure datanodes, user to run the datanode as after dropping privileges.</span></span><br><span class="line"><span class="comment"># This **MUST** be uncommented to enable secure HDFS if using privileged ports</span></span><br><span class="line"><span class="comment"># to provide authentication of data transfer protocol.  This **MUST NOT** be</span></span><br><span class="line"><span class="comment"># defined if SASL is configured for authentication of data transfer protocol</span></span><br><span class="line"><span class="comment"># using non-privileged ports.</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_SECURE_DN_USER=<span class="variable">$&#123;HADOOP_SECURE_DN_USER&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Where log files are stored.  $HADOOP_HOME/logs by default.</span></span><br><span class="line"><span class="comment">#export HADOOP_LOG_DIR=$&#123;HADOOP_LOG_DIR&#125;/$USER</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Where log files are stored in the secure data environment.</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_SECURE_DN_LOG_DIR=<span class="variable">$&#123;HADOOP_LOG_DIR&#125;</span>/<span class="variable">$&#123;HADOOP_HDFS_USER&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">###</span></span><br><span class="line"><span class="comment"># HDFS Mover specific parameters</span></span><br><span class="line"><span class="comment">###</span></span><br><span class="line"><span class="comment"># Specify the JVM options to be used when starting the HDFS Mover.</span></span><br><span class="line"><span class="comment"># These options will be appended to the options specified as HADOOP_OPTS</span></span><br><span class="line"><span class="comment"># and therefore may override any similar flags set in HADOOP_OPTS</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># export HADOOP_MOVER_OPTS=""</span></span><br><span class="line"></span><br><span class="line"><span class="comment">###</span></span><br><span class="line"><span class="comment"># Advanced Users Only!</span></span><br><span class="line"><span class="comment">###</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The directory where pid files are stored. /tmp by default.</span></span><br><span class="line"><span class="comment"># <span class="doctag">NOTE:</span> this should be set to a directory that can only be written to by </span></span><br><span class="line"><span class="comment">#       the user that will run the hadoop daemons.  Otherwise there is the</span></span><br><span class="line"><span class="comment">#       potential for a symlink attack.</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_PID_DIR=<span class="variable">$&#123;HADOOP_PID_DIR&#125;</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_SECURE_DN_PID_DIR=<span class="variable">$&#123;HADOOP_PID_DIR&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A string representing this instance of hadoop. $USER by default.</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_IDENT_STRING=<span class="variable">$USER</span></span><br></pre></td></tr></table></figure>
<p>也就是修改JDK路径<br><img src="https://img-blog.csdnimg.cn/20200327142029116.png" alt="在这里插入图片描述"><br><strong>注意：</strong> JAVA_HOME的路径按照你自己的路径来</p>
<h4 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;?xml version=<span class="string">"1.0"</span> encoding=<span class="string">"UTF-8"</span>?&gt;</span><br><span class="line">&lt;?xml-stylesheet <span class="built_in">type</span>=<span class="string">"text/xsl"</span> href=<span class="string">"configuration.xsl"</span>?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">  Licensed under the Apache License, Version 2.0 (the <span class="string">"License"</span>);</span><br><span class="line">  you may not use this file except <span class="keyword">in</span> compliance with the License.</span><br><span class="line">  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line">  Unless required by applicable law or agreed to <span class="keyword">in</span> writing, software</span><br><span class="line">  distributed under the License is distributed on an <span class="string">"AS IS"</span> BASIS,</span><br><span class="line">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">  See the License <span class="keyword">for</span> the specific language governing permissions and</span><br><span class="line">  limitations under the License. See accompanying LICENSE file.</span><br><span class="line">--&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- Put site-specific property overrides <span class="keyword">in</span> this file. --&gt;</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">      &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">		  &lt;value&gt;hdfs://hadoop01:9000&lt;/value&gt;</span><br><span class="line">      &lt;/property&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">       &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;/<span class="built_in">export</span>/servers/hadoop-2.7.7/tmp&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">      &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt;</span><br><span class="line">	    &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">     &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt;</span><br><span class="line">		 &lt;value&gt;*&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<h4 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;?xml version=<span class="string">"1.0"</span> encoding=<span class="string">"UTF-8"</span>?&gt;</span><br><span class="line">&lt;?xml-stylesheet <span class="built_in">type</span>=<span class="string">"text/xsl"</span> href=<span class="string">"configuration.xsl"</span>?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">  Licensed under the Apache License, Version 2.0 (the <span class="string">"License"</span>);</span><br><span class="line">  you may not use this file except <span class="keyword">in</span> compliance with the License.</span><br><span class="line">  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line">  Unless required by applicable law or agreed to <span class="keyword">in</span> writing, software</span><br><span class="line">  distributed under the License is distributed on an <span class="string">"AS IS"</span> BASIS,</span><br><span class="line">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">  See the License <span class="keyword">for</span> the specific language governing permissions and</span><br><span class="line">  limitations under the License. See accompanying LICENSE file.</span><br><span class="line">--&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- Put site-specific property overrides <span class="keyword">in</span> this file. --&gt;</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;3&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hadoop02:50090&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<p>fs.defaultFS表示我们对HDFS的访问路径<br>dfs.replication指定副本数量，也就是一个文件存几遍<br>dfs.namenode.secondary.http-address表示2nn的访问路径</p>
<h4 id="mapred-site-xml"><a href="#mapred-site-xml" class="headerlink" title="mapred-site.xml"></a>mapred-site.xml</h4><p>系统里面没有mapred-site.xml文件，则需要复制一个<br><code>cp mapred-site.xml.template mapred-site.xml</code></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;?xml version=<span class="string">"1.0"</span>?&gt;</span><br><span class="line">&lt;?xml-stylesheet <span class="built_in">type</span>=<span class="string">"text/xsl"</span> href=<span class="string">"configuration.xsl"</span>?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">  Licensed under the Apache License, Version 2.0 (the <span class="string">"License"</span>);</span><br><span class="line">  you may not use this file except <span class="keyword">in</span> compliance with the License.</span><br><span class="line">  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line">  Unless required by applicable law or agreed to <span class="keyword">in</span> writing, software</span><br><span class="line">  distributed under the License is distributed on an <span class="string">"AS IS"</span> BASIS,</span><br><span class="line">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">  See the License <span class="keyword">for</span> the specific language governing permissions and</span><br><span class="line">  limitations under the License. See accompanying LICENSE file.</span><br><span class="line">--&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- Put site-specific property overrides <span class="keyword">in</span> this file. --&gt;</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;!-- 指定MR运行在Yarn上 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt; </span><br><span class="line">  &lt;!-- 历史服务器端地址 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hadoop01:10020&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;!-- 历史服务器web端地址 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hadoop01:19888&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<h4 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;?xml version=<span class="string">"1.0"</span>?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">  Licensed under the Apache License, Version 2.0 (the <span class="string">"License"</span>);</span><br><span class="line">  you may not use this file except <span class="keyword">in</span> compliance with the License.</span><br><span class="line">  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line">  Unless required by applicable law or agreed to <span class="keyword">in</span> writing, software</span><br><span class="line">  distributed under the License is distributed on an <span class="string">"AS IS"</span> BASIS,</span><br><span class="line">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">  See the License <span class="keyword">for</span> the specific language governing permissions and</span><br><span class="line">  limitations under the License. See accompanying LICENSE file.</span><br><span class="line">--&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">	&lt;!-- Site specific YARN configuration properties --&gt;</span><br><span class="line">	&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;hadoop01&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;!-- Reducer获取数据的方式 --&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;!-- 日志聚集功能使能 --&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;<span class="literal">true</span>&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;</span><br><span class="line">	&lt;!-- 日志保留时间设置7天 --&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">		&lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;</span><br><span class="line">		&lt;value&gt;604800&lt;/value&gt;</span><br><span class="line">	&lt;/property&gt;	</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<h4 id="slaves"><a href="#slaves" class="headerlink" title="slaves"></a>slaves</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hadoop01</span><br><span class="line">hadoop02</span><br><span class="line">hadoop03</span><br></pre></td></tr></table></figure>
<h4 id="上传配置"><a href="#上传配置" class="headerlink" title="上传配置"></a>上传配置</h4><p>将以上修改的文件上传到服务器中：<br><strong>右键–&gt;SFTP/FTP–&gt;Upload File</strong><br>对应下图文件：<br>注意：只要是修改过的文件都需要Upload<br><img src="https://img-blog.csdnimg.cn/20200327142853963.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpdTEzNDAzMDgzNTA=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="配置文件分发"><a href="#配置文件分发" class="headerlink" title="配置文件分发"></a>配置文件分发</h3><p>让hadoop02、03和01保持一致</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scp /etc/profile hadoop02:/etc/profile</span><br><span class="line">scp /etc/profile hadoop03:/etc/profile</span><br><span class="line">scp -r /<span class="built_in">export</span>/ hadoop02:/</span><br><span class="line">scp -r /<span class="built_in">export</span>/ hadoop03:/</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20200327143347362.png?x-oss-process=image" alt="在这里插入图片描述"><br>scp /etc/profile hadoop02:/etc/profile这句是发环境变量<br>scp -r /export/ hadoop02:/这句是发hadoop整个文件夹</p>
<p><strong>注意：</strong> 命令执行完之后在hadoop02和hadoop03上执行<code>source /etc/profile</code></p>
<p>配置完以上的文件，那么集群基本配置就已经完成</p>
<h3 id="执行格式化"><a href="#执行格式化" class="headerlink" title="执行格式化"></a>执行格式化</h3><p>在hadoop01中执行下列命令<br><code>hdfs namenode -format</code><br><img src="https://img-blog.csdnimg.cn/20200327143553474.png?x-oss-process=image" alt="在这里插入图片描述"><br>在上图看到下图内容则说明文件配置成功<br><img src="https://img-blog.csdnimg.cn/20200327143544630.png" alt="在这里插入图片描述"></p>
<h3 id="查看hadoop信息"><a href="#查看hadoop信息" class="headerlink" title="查看hadoop信息"></a>查看hadoop信息</h3><p><img src="https://img-blog.csdnimg.cn/20200327143748685.png" alt="在这里插入图片描述"><br><strong>注意：</strong> 第一次进入没有data文件，需要启动namenode<br><img src="https://img-blog.csdnimg.cn/20200327143802429.png" alt="在这里插入图片描述"><br>下图是hadoop文件的树形结构：<br><img src="https://img-blog.csdnimg.cn/202003271451261.png?x-oss-process=image" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200327145141354.png?x-oss-process=image" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200327145153230.png?x-oss-process=image" alt="在这里插入图片描述"><br><strong>注意：</strong><br>如果想让文件显示树形结构，需要安装tree文件：<code>yum -y install tree</code><br><img src="https://img-blog.csdnimg.cn/20200327143812869.png" alt="在这里插入图片描述"><br>查看版本信息：clusterID必须保持一致<br><img src="https://img-blog.csdnimg.cn/2020032714382229.png" alt="在这里插入图片描述"><br><strong>注意：</strong><br>1.如果后面出现集群找不到数据的情况，那就是因为NameNode和DataNode的集群id不一致<br>2.格式化NameNode，会产生新的集群id</p>
<h3 id="启动HDFS和YARN"><a href="#启动HDFS和YARN" class="headerlink" title="启动HDFS和YARN"></a>启动HDFS和YARN</h3><p><img src="https://img-blog.csdnimg.cn/20200327145625866.png" alt="在这里插入图片描述"></p>
<p>hadoop01:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hadoop-daemon.sh start namenode</span><br><span class="line">hadoop-daemon.sh start datanode</span><br><span class="line">yarn-daemon.sh start resourcemanager</span><br><span class="line">yarn-daemon.sh start nodemanager</span><br></pre></td></tr></table></figure>

<p>hadoop02:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hadoop-daemon.sh start datanode</span><br><span class="line">yarn-daemon.sh start nodemanager</span><br><span class="line">在节点hadoop02执行指令启动SecondaryNameNode进程</span><br><span class="line">hadoop-daemon.sh start secondarynamenode</span><br></pre></td></tr></table></figure>

<p>hadoop03:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hadoop-daemon.sh start datanode</span><br><span class="line">yarn-daemon.sh start nodemanager</span><br></pre></td></tr></table></figure>

<h4 id="脚本一键启动"><a href="#脚本一键启动" class="headerlink" title="脚本一键启动"></a>脚本一键启动</h4><p>在主节点hadoop01上执行指令<code>start-dfs.sh</code>或<code>stop-dfs.sh</code>启动/关闭所有HDFS服务进程<br>在主节点hadoop01上执行指令<code>start-yarn.sh</code>或<code>stop-yarn.sh</code>启动/关闭所有YARN服务进程；<br>在主节点hadoop01上执行<code>start-all.sh</code>或<code>stop-all.sh</code>指令，直接启动/关闭整个Hadoop集群服务。</p>
<h4 id="查看是否启动"><a href="#查看是否启动" class="headerlink" title="查看是否启动"></a>查看是否启动</h4><p>hadoop01，02，03的情况如下图所示：<br>hadoop01:<br><img src="https://img-blog.csdnimg.cn/20200327150056763.png" alt="在这里插入图片描述"><br>hadoop02:<br><img src="https://img-blog.csdnimg.cn/20200327150104128.png" alt="在这里插入图片描述"><br>hadoop03:<br><img src="https://img-blog.csdnimg.cn/20200327150110367.png" alt="在这里插入图片描述"></p>
<h4 id="配置jps快捷键"><a href="#配置jps快捷键" class="headerlink" title="配置jps快捷键"></a>配置jps快捷键</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">创建文件夹 /root/bin</span><br><span class="line">touch jpsall</span><br><span class="line">vim jpsall</span><br><span class="line">chmod 777 jpsall</span><br></pre></td></tr></table></figure>
<p>jpsall文件内容如下：</p>
<figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> hadoop01 hadoop02 hadoop03</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">echo ===================== <span class="variable">$i</span> ======================</span><br><span class="line">ssh <span class="variable">$i</span> <span class="string">"source /etc/profile &amp;&amp; jps | grep -v Jps"</span></span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<p>配置完成就不再需要单独运行jps了<br><strong>测试：</strong><br><img src="https://img-blog.csdnimg.cn/20200327151641623.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<h4 id="游览器访问"><a href="#游览器访问" class="headerlink" title="游览器访问"></a>游览器访问</h4><p>Hadoop集群正常启动后，它默认开放了两个端口50070和8088 ，需要关闭防火墙才能访问</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">service iptables stop</span><br><span class="line">chkconfig iptables off</span><br></pre></td></tr></table></figure>
<p><strong>注意：</strong> hadoop02和hadoop03的防火墙也需要关闭<br>关闭防火墙之后，在游览器中输入下列网址即可访问：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">http://hadoop01:50070/</span><br><span class="line">http://hadoop01:8088</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20200327150457137.png?x-oss-process=image" alt="在这里插入图片描述"><br>检查3个datanode是否显示：<br><img src="https://img-blog.csdnimg.cn/20200327150537481.png?x-oss-process=image" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200327150555548.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<h3 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h3><p>执行命令报错：<br><code>export HADOOP_ROOT_LOGGER=DEBUG,console
hdfs dfs -ls /</code><br><img src="https://img-blog.csdnimg.cn/20200327151905501.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200327151915561.png" alt="在这里插入图片描述"><br>查阅debug报错信息，可以看到问题是glib版本不够</p>
<h4 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h4><h5 id="1-下载对应文件"><a href="#1-下载对应文件" class="headerlink" title="1.下载对应文件"></a>1.下载对应文件</h5><p>下载glibc-2.14.tar.bz2<br>地址为：<a href="http://ftp.ntu.edu.tw/gnu/glibc/" target="_blank" rel="noopener">http://ftp.ntu.edu.tw/gnu/glibc/</a><br>下载glibc-linuxthreads-2.5.tar.bz2<br>地址为：<a href="http://ftp.ntu.edu.tw/gnu/glibc/" target="_blank" rel="noopener">http://ftp.ntu.edu.tw/gnu/glibc/</a></p>
<h5 id="2-安装"><a href="#2-安装" class="headerlink" title="2. 安装"></a>2. 安装</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install gcc</span><br><span class="line">tar -xjvf glibc-2.14.tar.bz2</span><br><span class="line"><span class="built_in">cd</span> glibc-2.14</span><br><span class="line">tar -xjvf ../glibc-linuxthreads-2.5.tar.bz2</span><br><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line"><span class="built_in">export</span> CFLAGS=<span class="string">"-g -O2"</span></span><br><span class="line">glibc-2.14/configure --prefix=/usr --<span class="built_in">disable</span>-profile --<span class="built_in">enable</span>-add-ons -</span><br><span class="line">-with-headers=/usr/include --with-binutils=/usr/bin --<span class="built_in">disable</span>-sanitychecks</span><br><span class="line">make//编译，执行很久(5-10分钟)，可能出错，出错再重新执行</span><br><span class="line">make install</span><br><span class="line">ll /lib64/libc.so.6</span><br></pre></td></tr></table></figure>
<h4 id="测试："><a href="#测试：" class="headerlink" title="测试："></a>测试：</h4><p><img src="https://img-blog.csdnimg.cn/2020032715242188.png" alt="在这里插入图片描述"></p>
<h3 id="测试集群"><a href="#测试集群" class="headerlink" title="测试集群"></a>测试集群</h3><p><img src="https://img-blog.csdnimg.cn/20200327152654363.png" alt="在这里插入图片描述"><br>可知集群已经上hdfs了：<br><img src="https://img-blog.csdnimg.cn/20200327152702853.png?x-oss-process=image" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200327152719538.png" alt="在这里插入图片描述"></p>
<p>由下图可知集群测试成功：<br>看到3个备份，集群数据统一<br><img src="https://img-blog.csdnimg.cn/20200327152854544.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hadoop jar hadoop-mapreduce-examples-2.7.7.jar wordcount /wordcount/input /wordcount/output</span><br></pre></td></tr></table></figure>
<p><strong>注意:</strong> output文件不能存在<br><img src="https://img-blog.csdnimg.cn/20200327153113296.png?x-oss-process=image" alt="在这里插入图片描述"><br>到这一步为止，表示集群运行正常</p>
<h3 id="配置历史服务器"><a href="#配置历史服务器" class="headerlink" title="配置历史服务器"></a>配置历史服务器</h3><p><img src="https://img-blog.csdnimg.cn/20200327154728635.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200327154806819.png" alt="在这里插入图片描述"><br>可以看到无法访问页面：</p>
<p><img src="https://img-blog.csdnimg.cn/20200327154856858.png?x-oss-process=image" alt="在这里插入图片描述"><br>这里就需要继续编辑vim mapred-site.xml文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;!-- 历史服务器端地址 --&gt; </span><br><span class="line">&lt;property&gt; </span><br><span class="line">&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; </span><br><span class="line">&lt;value&gt;hadoop01:10020&lt;/value&gt; </span><br><span class="line">&lt;/property&gt; </span><br><span class="line">&lt;!-- 历史服务器web端地址 --&gt; </span><br><span class="line">&lt;property&gt; </span><br><span class="line">    &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; </span><br><span class="line">    &lt;value&gt;hadoop01:19888&lt;/value&gt; </span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<p>启动历史服务器<br><code>mr-jobhistory-daemon.sh start historyserver</code></p>
<p>可以看到下图显示：<br><img src="https://img-blog.csdnimg.cn/2020032715502952.png?x-oss-process=image" alt="在这里插入图片描述"></p>
<h3 id="日志聚集"><a href="#日志聚集" class="headerlink" title="日志聚集"></a>日志聚集</h3><p><strong>目的：</strong> 应用运行完成以后，将程序运行日志信息上传到HDFS系统上。</p>
<p>这里需要配置yarn-site.xml</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;!-- 日志聚集功能使能 --&gt; </span><br><span class="line">&lt;property&gt; </span><br><span class="line">&lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; </span><br><span class="line">&lt;value&gt;<span class="literal">true</span>&lt;/value&gt; </span><br><span class="line">&lt;/property&gt; </span><br><span class="line">&lt;!-- 日志保留时间设置7天 --&gt; </span><br><span class="line">&lt;property&gt; </span><br><span class="line">&lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; </span><br><span class="line">&lt;value&gt;604800&lt;/value&gt; </span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<p>1.重启NodeManager 、ResourceManager和HistoryServer<br>2..删除HDFS上已经存在的输出文件<br><code>hdfs dfs -rm -R /wordcount/output</code><br>3.执行WordCount程序<br>4.查看日志聚集<br>点击log文件<br><img src="https://img-blog.csdnimg.cn/20200327155302493.png" alt="在这里插入图片描述"><br>可以看到：<br><img src="https://img-blog.csdnimg.cn/20200327155318637.png?x-oss-process=image" alt="在这里插入图片描述"><br>那么现在开始，每个任务都开起了实时日志收集功能，日志保存7天，全部可以在cluster中查看了</p>
<h3 id="集群时间同步"><a href="#集群时间同步" class="headerlink" title="集群时间同步"></a>集群时间同步</h3><p>这里以hadoop01作为基准时间，02、03跟他一致</p>
<h4 id="1-查看是否有ntp文件，系统默认安装"><a href="#1-查看是否有ntp文件，系统默认安装" class="headerlink" title="1.查看是否有ntp文件，系统默认安装"></a>1.查看是否有ntp文件，系统默认安装</h4><p><code>rpm -qa|grep ntp</code><br><img src="https://img-blog.csdnimg.cn/20200327160254904.png" alt="在这里插入图片描述"></p>
<h4 id="2-vim-etc-ntp-conf"><a href="#2-vim-etc-ntp-conf" class="headerlink" title="2.vim /etc/ntp.conf"></a>2.vim /etc/ntp.conf</h4><p><img src="https://img-blog.csdnimg.cn/2020032716040257.png?x-oss-process=image" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200327160414790.png?x-oss-process=image" alt="在这里插入图片描述"><br>修改点：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">1、授权192.168.1.0-192.168.1.255网段上的所有机器可以从这台机器上查询和同步时间</span><br><span class="line">将  <span class="comment">#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap为</span></span><br><span class="line">restrict 192.168.200.0 mask 255.255.255.0 nomodify notrap</span><br><span class="line"></span><br><span class="line">2、集群在局域网中，不使用其他互联网上的时间</span><br><span class="line">server 0.centos.pool.ntp.org iburst</span><br><span class="line"></span><br><span class="line">server 1.centos.pool.ntp.org iburst</span><br><span class="line"></span><br><span class="line">server 2.centos.pool.ntp.org iburst</span><br><span class="line"></span><br><span class="line">server 3.centos.pool.ntp.org iburst</span><br><span class="line"></span><br><span class="line">为</span><br><span class="line"></span><br><span class="line"><span class="comment">#server 0.centos.pool.ntp.org iburst</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#server 1.centos.pool.ntp.org iburst</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#server 2.centos.pool.ntp.org iburst</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#server 3.centos.pool.ntp.org iburst</span></span><br><span class="line"></span><br><span class="line">3、当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步</span><br><span class="line">server 127.127.1.0</span><br><span class="line"></span><br><span class="line">fudge 127.127.1.0 stratum 10</span><br></pre></td></tr></table></figure>
<h4 id="3-vim-etc-sysconfig-ntpd"><a href="#3-vim-etc-sysconfig-ntpd" class="headerlink" title="3.vim /etc/sysconfig/ntpd"></a>3.vim /etc/sysconfig/ntpd</h4><p>让硬件时间与系统时间一起同步<code>SYNC_HWCLOCK=yes</code><br><img src="https://img-blog.csdnimg.cn/20200327160618712.png" alt="在这里插入图片描述"><br>配置文件保存之后</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">重新启动ntpd服务</span><br><span class="line">service ntpd status</span><br><span class="line"></span><br><span class="line">设置ntpd服务开机启动</span><br><span class="line">chkconfig ntpd on</span><br></pre></td></tr></table></figure>

<h4 id="4-在hadoop2和hadoop3上配置"><a href="#4-在hadoop2和hadoop3上配置" class="headerlink" title="4.在hadoop2和hadoop3上配置"></a>4.在hadoop2和hadoop3上配置</h4><p><code>crontab -e</code> </p>
<p>输入:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">*/10 * * * * /usr/sbin/ntpdate hadoop01</span><br></pre></td></tr></table></figure>
<p>这样会让hadoop02和hadoop03每10分钟与时间服务器同步一次</p>
<h4 id="5-测试"><a href="#5-测试" class="headerlink" title="5.测试"></a>5.测试</h4><p>修改hadoop02的当前时间：<br><img src="https://img-blog.csdnimg.cn/20200327160931558.png" alt="在这里插入图片描述"><br>然后输入<code>mail</code>,系统会提示时间已经修改<br><img src="https://img-blog.csdnimg.cn/20200327161036874.png?x-oss-process=image" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200327161056816.png?x-oss-process=image" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>Hadoop集群</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Java集合</title>
    <url>/2020/08/05/Java%E9%9B%86%E5%90%88/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Collection</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Collection</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis集群搭建</title>
    <url>/2020/07/30/Redis%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<h3 id="1、Redis集群方案比较"><a href="#1、Redis集群方案比较" class="headerlink" title="1、Redis集群方案比较"></a>1、Redis集群方案比较</h3><ul>
<li><strong>哨兵模式</strong></li>
</ul>
<p><img src="https://static.oschina.net/uploads/img/201803/29191414_Dwf2.jpg" alt="img"></p>
<p>在redis3.0以前的版本要实现集群一般是借助哨兵sentinel工具来监控master节点的状态，如果master节点异常，则会做主从切换，将某一台slave作为master，哨兵的配置略微复杂，并且性能和高可用性等各方面表现一般，特别是在主从切换的瞬间存在访问瞬断的情况</p>
<a id="more"></a>
<ul>
<li><strong>高可用集群模式</strong></li>
</ul>
<p><img src="https://static.oschina.net/uploads/space/2018/0330/181526_7mpT_3796575.png" alt="img"></p>
<p>redis集群是一个由多个主从节点群组成的分布式服务器群，它具有复制、高可用和分片特性。Redis集群不需要sentinel哨兵也能完成节点移除和故障转移的功能。需要将每个节点设置成集群模式，这种集群模式没有中心节点，可水平扩展，据官方文档称可以线性扩展到1000节点。redis集群的性能和高可用性均优于之前版本的哨兵模式，且集群配置非常简单。</p>
<h3 id="2、redis高可用集群搭建"><a href="#2、redis高可用集群搭建" class="headerlink" title="2、redis高可用集群搭建"></a>2、redis高可用集群搭建</h3><ul>
<li><strong>redis安装</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">下载地址：http:&#x2F;&#x2F;redis.io&#x2F;download</span><br><span class="line">安装步骤：</span><br><span class="line"># 安装gcc</span><br><span class="line">yum install gcc</span><br><span class="line"></span><br><span class="line"># 把下载好的redis-3.0.0-rc2.tar.gz放在&#x2F;usr&#x2F;local文件夹下，并解压</span><br><span class="line">tar -zxvf redis-3.0.0-rc2.tar.gz</span><br><span class="line"></span><br><span class="line"># 进入到解压好的redis-3.0.0目录下，进行编译</span><br><span class="line">make</span><br><span class="line"></span><br><span class="line"># 进入到redis-3.0.0&#x2F;src目录下进行安装，安装完成验证src目录下是否已经生成了redis-server 、redis-cil</span><br><span class="line">make install</span><br><span class="line"></span><br><span class="line"># 建立俩个文件夹存放redis命令和配置文件</span><br><span class="line">mkdir -p &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc</span><br><span class="line">mkdir -p &#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin</span><br><span class="line"></span><br><span class="line"># 把redis-3.0.0下的redis.conf复制到&#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc下</span><br><span class="line">cp redis.conf &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc&#x2F;</span><br><span class="line"></span><br><span class="line"># 移动redis-3.0.0&#x2F;src里的几个文件到&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin下</span><br><span class="line">mv mkreleasehdr.sh redis-benchmark redis-check-aof redis-check-dump redis-cli redis-server &#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin</span><br><span class="line"></span><br><span class="line"># 启动并指定配置文件</span><br><span class="line">&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-server &#x2F;usr&#x2F;local&#x2F;redis&#x2F;etc&#x2F;redis.conf（注意要使用后台启动，所以修改redis.conf里的daemonize改为yes)</span><br><span class="line"></span><br><span class="line"># 验证启动是否成功</span><br><span class="line">ps -ef | grep redis </span><br><span class="line"></span><br><span class="line"># 查看是否有redis服务或者查看端口</span><br><span class="line">netstat -tunpl | grep 6379</span><br><span class="line"></span><br><span class="line"># 进入redis客户端 </span><br><span class="line">&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-cli </span><br><span class="line"></span><br><span class="line"># 退出客户端</span><br><span class="line">quit</span><br><span class="line"></span><br><span class="line"># 退出redis服务： </span><br><span class="line">（1）pkill redis-server </span><br><span class="line">（2）kill 进程号                       </span><br><span class="line">（3）&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-cli shutdown</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>redis集群搭建</strong></li>
</ul>
<p>redis集群需要至少要三个master节点，我们这里搭建三个master节点，并且给每个master再搭建一个slave节点，总共6个redis节点，由于节点数较多，这里采用在一台机器上创建6个redis实例，并将这6个redis实例配置成集群模式，所以这里搭建的是伪分布式集群模式，当然真正的分布式集群的配置方法几乎一样，搭建伪分布式集群的步骤如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">第一步：在&#x2F;usr&#x2F;local下创建文件夹redis-cluster，然后在其下面分别创建6个文件夾如下</span><br><span class="line">（1）mkdir -p &#x2F;usr&#x2F;local&#x2F;redis-cluster</span><br><span class="line">（2）mkdir 8001、 mkdir 8002、 mkdir 8003、 mkdir 8004、 mkdir 8005、 mkdir 8006</span><br><span class="line"></span><br><span class="line">第一步：把之前的redis.conf配置文件copy到8001下，修改如下内容：</span><br><span class="line">（1）daemonize yes</span><br><span class="line">（2）port 8001（分别对每个机器的端口号进行设置）</span><br><span class="line">（3）bind 192.168.0.61（必须要绑定当前机器的ip，这里方便redis集群定位机器，不绑定可能会出现循环查找集群节点机器的情况）</span><br><span class="line">（4）dir &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;8001&#x2F;（指定数据文件存放位置，必须要指定不同的目录位置，不然会丢失数据）</span><br><span class="line">（5）cluster-enabled yes（启动集群模式）</span><br><span class="line">（6）cluster-config-file nodes-8001.conf（这里800x最好和port对应上）</span><br><span class="line">（7）cluster-node-timeout 5000</span><br><span class="line">（8）appendonly yes</span><br><span class="line"></span><br><span class="line">第三步：把修改后的配置文件，分别 copy到各个文夹下，注意每个文件要修改第2、4、6项里的端口号</span><br><span class="line">快捷复制命令：%s&#x2F;原目标&#x2F;目标地址&#x2F;g    </span><br><span class="line">第四步：由于 redis集群需要使用 ruby命令，所以我们需要安装 ruby</span><br><span class="line">（1）yum install ruby</span><br><span class="line">（2）yum install rubygems</span><br><span class="line">（3）gem install redis --version 3.0.0（安装redis和 ruby的接囗）</span><br><span class="line"></span><br><span class="line">第五步：分别启动6个redis实例，然后检查是否启动成功</span><br><span class="line">（1）&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-server &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;800*&#x2F;redis.conf</span><br><span class="line">（2）ps -ef | grep redis 查看是否启动成功</span><br><span class="line"></span><br><span class="line">第六步：在redis的安装目录下执行 redis-trib.rb命令</span><br><span class="line">（1）cd &#x2F;usr&#x2F;local&#x2F;redis-3.0.0&#x2F;src</span><br><span class="line">（2）.&#x2F;redis-trib.rb create --replicas 1 192.168.0.61:8001 192.168.0.61:8002 192.168.0.61:8003 192.168.0.61:8004 192.168.0.61:8005 192.168.0.61:8006</span><br><span class="line">新版本：redis-cli --cluster create 192.168.200.10:8001 192.168.200.10:8002  192.168.200.10:8003 192.168.200.10:8004 192.168.200.10:8005 192.168.200.10:8006  --cluster-replicas 1</span><br><span class="line"></span><br><span class="line">第七步：验证集群：</span><br><span class="line">（1）连接任意一个客户端即可：.&#x2F;redis-cli -c -h -p (-c表示集群模式，指定ip地址和端口号）如：&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-cli -c -h 192.168.0.61 -p 800*</span><br><span class="line">（2）进行验证： cluster info（查看集群信息）、cluster nodes（查看节点列表）</span><br><span class="line">（3）进行数据操作验证</span><br><span class="line">（4）关闭集群则需要逐个进行关闭，使用命令：</span><br><span class="line">&#x2F;usr&#x2F;local&#x2F;redis&#x2F;bin&#x2F;redis-cli -c -h 192.168.0.61 -p 800* shutdown</span><br><span class="line"></span><br><span class="line">PS：当出现集群无法启动时，删除redis的临时数据文件，再次重新启动每一个redis服务，然后重新构造集群环境。</span><br></pre></td></tr></table></figure>



<h3 id="3、Java操作redis集群"><a href="#3、Java操作redis集群" class="headerlink" title="3、Java操作redis集群"></a>3、Java操作redis集群</h3><p>借助redis的java客户端jedis可以操作以上集群，引用jedis版本的maven坐标如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;redis.clients&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;jedis&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.9.0&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>

<p>Java编写访问redis集群的代码非常简单，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import java.io.IOException;</span><br><span class="line">import java.util.HashSet;</span><br><span class="line">import java.util.Set;</span><br><span class="line"></span><br><span class="line">import redis.clients.jedis.HostAndPort;</span><br><span class="line">import redis.clients.jedis.JedisCluster;</span><br><span class="line">import redis.clients.jedis.JedisPoolConfig;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 访问redis集群</span><br><span class="line"> * @author aaron.rao</span><br><span class="line"> *</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class RedisCluster </span><br><span class="line">&#123;</span><br><span class="line">    public static void main(String[] args) throws IOException</span><br><span class="line">    &#123;</span><br><span class="line">        Set&lt;HostAndPort&gt; jedisClusterNode &#x3D; new HashSet&lt;HostAndPort&gt;();</span><br><span class="line">        jedisClusterNode.add(new HostAndPort(&quot;192.168.0.61&quot;, 8001));</span><br><span class="line">        jedisClusterNode.add(new HostAndPort(&quot;192.168.0.61&quot;, 8002));</span><br><span class="line">        jedisClusterNode.add(new HostAndPort(&quot;192.168.0.61&quot;, 8003));</span><br><span class="line">        jedisClusterNode.add(new HostAndPort(&quot;192.168.0.61&quot;, 8004));</span><br><span class="line">        jedisClusterNode.add(new HostAndPort(&quot;192.168.0.61&quot;, 8005));</span><br><span class="line">        jedisClusterNode.add(new HostAndPort(&quot;192.168.0.61&quot;, 8006));</span><br><span class="line">        </span><br><span class="line">        JedisPoolConfig config &#x3D; new JedisPoolConfig();</span><br><span class="line">        config.setMaxTotal(100);</span><br><span class="line">        config.setMaxIdle(10);</span><br><span class="line">        config.setTestOnBorrow(true);</span><br><span class="line">        JedisCluster jedisCluster &#x3D; new JedisCluster(jedisClusterNode, 6000, 10, config);</span><br><span class="line">        System.out.println(jedisCluster.set(&quot;student&quot;, &quot;aaron&quot;));</span><br><span class="line">        System.out.println(jedisCluster.set(&quot;age&quot;, &quot;18&quot;));</span><br><span class="line">        </span><br><span class="line">        System.out.println(jedisCluster.get(&quot;student&quot;));</span><br><span class="line">        System.out.println(jedisCluster.get(&quot;age&quot;));</span><br><span class="line">        </span><br><span class="line">        jedisCluster.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">运行效果如下：</span><br><span class="line">OK</span><br><span class="line">OK</span><br><span class="line">aaron</span><br><span class="line">18</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Redis集群</category>
      </categories>
      <tags>
        <tag>Redis集群</tag>
      </tags>
  </entry>
  <entry>
    <title>error: failed to push some refs to git@github.com:liuurick/BlogBackup.git</title>
    <url>/2019/07/30/error%20failed%20to%20push%20some%20refs%20to%20git/</url>
    <content><![CDATA[<p>git push的时候报错：</p>
<blockquote>
<p>! [rejected]        master -&gt; master (fetch first)<br>error: failed to push some refs to ‘git@github.com:liuurick/BlogBackup.git’<br>hint: Updates were rejected because the remote contains work that you do<br>hint: not have locally. This is usually caused by another repository pushing<br>hint: to the same ref. You may want to first integrate the remote changes<br>hint: (e.g., ‘git pull …’) before pushing again.<br>hint: See the ‘Note about fast-forwards’ in ‘git push –help’ for details.</p>
</blockquote>
<p>查了几种解决方式都不太管用，最后发现是由于github中的README.md文件不在本地代码目录中</p>
<p>检查了一下果然如此！<br>这时候可以通过 <code>git pull --rebase origin master</code> 把README.md文件克隆到本地库。</p>
<p>git pull –rebase origin master<br>最后提交：<code>git push origin master</code></p>
]]></content>
      <categories>
        <category>git常见错误</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>fatal: not a git repository (or any of the parent directories): .git</title>
    <url>/2019/07/28/fatal%20not%20a%20git%20repository%20or%20any%20of%20the%20parent%20directories%20git/</url>
    <content><![CDATA[<p>一般是没有初始化git本地版本管理仓库，所以无法执行git命令 </p>
<h3 id="解决方法："><a href="#解决方法：" class="headerlink" title="解决方法："></a>解决方法：</h3><p>操作之前执行以下命令行: <code>git init</code><br>然后执行一下<code>git status</code>查看状态信息</p>
]]></content>
      <categories>
        <category>git常见错误</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>git Could not read from remote repository</title>
    <url>/2019/07/20/git%20Could%20not%20read%20from%20remote%20repository/</url>
    <content><![CDATA[<p>git remote add origin <a href="mailto:git@github.com">git@github.com</a>:liuurick/BlogBackup.git</p>
<p>git remote -v</p>
<p>git bash输出</p>
]]></content>
      <categories>
        <category>git常见错误</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx安装及其配置</title>
    <url>/2020/07/31/nginx%E5%AE%89%E8%A3%85%E5%8F%8A%E5%85%B6%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<h1 id="1-nginx-介绍"><a href="#1-nginx-介绍" class="headerlink" title="1 nginx 介绍"></a>1 nginx 介绍</h1><h2 id="1-什么是nginx"><a href="#1-什么是nginx" class="headerlink" title="1 什么是nginx"></a>1 什么是nginx</h2><p>Nginx是一款高性能的http 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器。</p>
<p>由俄罗斯的程序设计师Igor Sysoev所开发，官方测试nginx能够支支撑5万并发链接，</p>
<p>并且cpu、内存等资源消耗却非常低，运行非常稳定。</p>
<a id="more"></a> 

<h2 id="2-应用场景"><a href="#2-应用场景" class="headerlink" title="2 应用场景"></a>2 应用场景</h2><p>1、http服务器。Nginx是一个http服务可以独立提供http服务。可以做网页静态服务器。</p>
<p>2、虚拟主机。可以实现在一台服务器虚拟出多个网站。例如个人网站使用的虚拟主机。</p>
<p>3、反向代理，负载均衡。当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，</p>
<p>需要用多台服务器集群可以使用nginx做反向代理。并且多台服务器可以平均分担负载，</p>
<p>不会因为某台服务器负载高宕机而某台服务器闲置的情况。</p>
<h1 id="2-nginx安装"><a href="#2-nginx安装" class="headerlink" title="2 nginx安装"></a>2 nginx安装</h1><h2 id="1-下载"><a href="#1-下载" class="headerlink" title="1 下载"></a>1 下载</h2><p>官方网址：<a href="http://nginx.org/en/download.html" target="_blank" rel="noopener">http://nginx.org/en/download.html</a></p>
<p>官网提供三种版本：</p>
<p>Nginx官网提供了三个类型的版本<br>Mainline version：Mainline 是 Nginx 目前主力在做的版本，可以说是开发版<br>Stable version：最新稳定版，生产环境上建议使用的版本<br>Legacy versions：遗留的老版本的稳定版</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528200317474-243156008.png" alt="img"></p>
<p>我们这里下载的是Stable version下面的</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528200502469-1278177452.png" alt="img"></p>
<p>使用的版本是1.14.0.tar.gz.</p>
<h2 id="2-安装要求的环境"><a href="#2-安装要求的环境" class="headerlink" title="2 安装要求的环境"></a>2 安装要求的环境</h2><p>下面的环境需要视自己的系统情况而定，没有的环境安装以下就好。</p>
<p><strong>1.需要安装gcc环境</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># yum install gcc-c++</span><br></pre></td></tr></table></figure>

<p><strong>2.第三方的开发包</strong></p>
<p><strong>1 PERE</strong></p>
<p>PCRE(Perl Compatible Regular Expressions)是一个Perl库，包括 perl 兼容的正则表达式库。</p>
<p>nginx的http模块使用pcre来解析正则表达式，所以需要在linux上安装pcre库。</p>
<p><strong>注：pcre-devel是使用pcre开发的一个二次开发库。nginx**</strong>也需要此库**。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># yum install -y pcre pcre-devel</span><br></pre></td></tr></table></figure>

<p><strong>2 zlib</strong></p>
<p>zlib库提供了很多种压缩和解压缩的方式，nginx使用zlib对http包的内容进行gzip，所以需要在linux上安装zlib库。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># yum install -y zlib zlib-devel</span><br></pre></td></tr></table></figure>

<p><strong>3 openssl</strong></p>
<p>OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，</p>
<p>并提供丰富的应用程序供测试或其它目的使用。</p>
<p>nginx不仅支持http协议，还支持https（即在ssl协议上传输http），所以需要在linux安装openssl库。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># yum -y install pcre  pcre-devel zlib  zlib-devel openssl openssl-devel</span><br></pre></td></tr></table></figure>

<h2 id="3-nginx安装过程"><a href="#3-nginx安装过程" class="headerlink" title="3 nginx安装过程"></a>3 nginx安装过程</h2><p><strong>1 把nginx源码包上传到linux系统上</strong></p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528213653887-1061022351.png" alt="img"></p>
<p><strong>2 解压到/usr/local下面</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># tar -xvf nginx-1.14.0.tar.gz -C &#x2F;usr&#x2F;local</span><br></pre></td></tr></table></figure>

<p><strong>3 使用cofigure命令创建一个makeFile文件</strong></p>
<p><strong>执行下面的命令的时候，一定要进入到nginx-1.14.0目录里面去。</strong></p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201806/1320077-20180603221011496-2060500005.png" alt="img"></p>
<p><a href="javascript:void(0);"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;configure \</span><br><span class="line">--prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx \</span><br><span class="line">--pid-path&#x3D;&#x2F;var&#x2F;run&#x2F;nginx&#x2F;nginx.pid \</span><br><span class="line">--lock-path&#x3D;&#x2F;var&#x2F;lock&#x2F;nginx.lock \</span><br><span class="line">--error-log-path&#x3D;&#x2F;var&#x2F;log&#x2F;nginx&#x2F;error.log \</span><br><span class="line">--http-log-path&#x3D;&#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log \</span><br><span class="line">--with-http_gzip_static_module \</span><br><span class="line">--http-client-body-temp-path&#x3D;&#x2F;var&#x2F;temp&#x2F;nginx&#x2F;client \</span><br><span class="line">--http-proxy-temp-path&#x3D;&#x2F;var&#x2F;temp&#x2F;nginx&#x2F;proxy \</span><br><span class="line">--http-fastcgi-temp-path&#x3D;&#x2F;var&#x2F;temp&#x2F;nginx&#x2F;fastcgi \</span><br><span class="line">--http-uwsgi-temp-path&#x3D;&#x2F;var&#x2F;temp&#x2F;nginx&#x2F;uwsgi \</span><br><span class="line">--http-scgi-temp-path&#x3D;&#x2F;var&#x2F;temp&#x2F;nginx&#x2F;scgi \--with-http_stub_status_module \--with-http_ssl_module \--with-file-aio \--with-http_realip_module</span><br></pre></td></tr></table></figure>

<p><a href="javascript:void(0);"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p>如果没有makeFile文件，编译的时候会报错</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528214718704-1940031525.png" alt="img"></p>
<p>\ 表示命令还没有输入完，换行的意思。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx  表示软件安装到&#x2F;usr&#x2F;local&#x2F;nginx下面。</span><br><span class="line">这个make install 的时候就不用在指定安装路径。</span><br><span class="line">执行完成后查看目录里面已经多了一个Makefile文件</span><br></pre></td></tr></table></figure>

<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528214847419-87432766.png" alt="img"></p>
<p><strong>注意：启动nginx之前，上边将临时文件目录指定为/var/temp/nginx，</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">需要在&#x2F;var下创建temp及nginx目</span><br></pre></td></tr></table></figure>

<p><strong>4 创建目录/var/temp/nginx/</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># mkdir &#x2F;var&#x2F;temp&#x2F;nginx -p</span><br></pre></td></tr></table></figure>

<p>-p 表示级联创建的意思</p>
<p><strong>5 进入nginx-1.14.0里面执行make命令进行编译</strong></p>
<p> <img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528215034813-1051731312.png" alt="img"></p>
<p><strong>6 进入nginx-1.14.0里面执行make install 命令进行安装</strong></p>
<p> 这里不需要再次执行安装路径，创建makefile文件的时候已经指定了。</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528215201682-241819080.png" alt="img"></p>
<p><strong>7 进入安装位置/usr/local/nginx查看目录结构</strong></p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528215317140-1292141060.png" alt="img"></p>
<p>其中html是里面首页html文件。conf里面是配置文件。sbin里面只执行文件。</p>
<h1 id="3-启动nginx"><a href="#3-启动nginx" class="headerlink" title="3 启动nginx"></a>3 启动nginx</h1><p>进入sbin目录，执行命令./nginx</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@admin sbin]# .&#x2F;nginx</span><br></pre></td></tr></table></figure>

<h1 id="4-查看nginx是否启动"><a href="#4-查看nginx是否启动" class="headerlink" title="4 查看nginx是否启动"></a>4 查看nginx是否启动</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@admin sbin]# ps -aux | grep nginx</span><br></pre></td></tr></table></figure>

<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528215659486-386960152.png" alt="img"></p>
<p><strong>ps命令</strong>用于报告当前系统的进程状态。</p>
<p>-a：显示所有终端机下执行的程序，除了阶段作业领导者之外。</p>
<p>a：显示现行终端机下的所有程序，包括其他用户的程序。</p>
<p>u：以用户为主的格式来显示程序状况。</p>
<p>x：显示所有程序，不以终端机来区分。</p>
<h1 id="5-关闭nginx"><a href="#5-关闭nginx" class="headerlink" title="5 关闭nginx"></a>5 关闭nginx</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@admin sbin]#  .&#x2F;nginx -s stop</span><br></pre></td></tr></table></figure>

<p>或者</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@admin sbin]# .&#x2F;nginx -s quit</span><br></pre></td></tr></table></figure>



<h1 id="6-重启nginx"><a href="#6-重启nginx" class="headerlink" title="6 重启nginx"></a>6 重启nginx</h1><p>先关闭，然后启动</p>
<h1 id="7-刷新配置文件"><a href="#7-刷新配置文件" class="headerlink" title="7 刷新配置文件"></a>7 刷新配置文件</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@admin sbin]# .&#x2F;nginx -s reload</span><br></pre></td></tr></table></figure>



<h1 id="8-关闭防火墙，开启远程访问"><a href="#8-关闭防火墙，开启远程访问" class="headerlink" title="8 关闭防火墙，开启远程访问"></a>8 关闭防火墙，开启远程访问</h1><p>首先需要关闭防火墙：默认端口是80</p>
<p><strong>方法一：永久开放80端口</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;sbin&#x2F;iptables -I INPUT -p tcp --dport 80 -j ACCEPT</span><br><span class="line">&#x2F;etc&#x2F;rc.d&#x2F;init.d&#x2F;iptables save</span><br></pre></td></tr></table></figure>

<p><strong>方法二：临时关闭系统防火墙</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># service iptables stop</span><br></pre></td></tr></table></figure>

<p><strong>方法三：永久关闭修改配置开机不启动防火墙</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># chkconfig iptables off</span><br></pre></td></tr></table></figure>

<p><strong>特殊：针对阿里云</strong></p>
<p>需要添加安全组规则</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528220957160-1215262173.png" alt="img"></p>
<h1 id="9-访问nginx"><a href="#9-访问nginx" class="headerlink" title="9 访问nginx"></a>9 访问nginx</h1><p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528221109414-1467990812.png" alt="img"></p>
<h1 id="10-配置虚拟主机"><a href="#10-配置虚拟主机" class="headerlink" title="10 配置虚拟主机"></a>10 配置虚拟主机</h1><p>就是在一台服务器启动多个网站。</p>
<p>如何区分不同的网站：主要有以下两种方式</p>
<p>方式一：端口不同</p>
<p>方式二：域名不同</p>
<h1 id="11-通过端口区分不同的主机"><a href="#11-通过端口区分不同的主机" class="headerlink" title="11 通过端口区分不同的主机"></a>11 通过端口区分不同的主机</h1><p>nginx配置文件的位置：/usr/local/nginx/conf/nginx.conf</p>
<p>原始配置文件的内容如下：</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528231052645-411882308.png" alt="img"></p>
<p>我们可以通过配置多个server,从而配置多个虚拟机</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528231338064-1303784911.png" alt="img"></p>
<p>下面测试以下：复制原来的html目录，改名为html-81</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528225829702-501478470.png" alt="img"></p>
<p>修改以下里面的index.html文件，方便区分</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@admin nginx]# vim html-81&#x2F;index.html</span><br></pre></td></tr></table></figure>

<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528230030494-1928427070.png" alt="img"></p>
<p>修改完成之后刷新以下配置文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@admin sbin]# .&#x2F;nginx -s reload</span><br></pre></td></tr></table></figure>

<p>然后分别访问192.168.204.131:80 和192.168.204.131:81</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528231556841-1742041295.png" alt="img"></p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528231650473-1839844366.png" alt="img"></p>
<h1 id="12-多个域名区分虚拟主机"><a href="#12-多个域名区分虚拟主机" class="headerlink" title="12 多个域名区分虚拟主机"></a>12 多个域名区分虚拟主机</h1><h2 id="1-什么是域名"><a href="#1-什么是域名" class="headerlink" title="1 什么是域名"></a>1 什么是域名</h2><p>域名就是网站：<a href="http://www.baidu.com就是域名" target="_blank" rel="noopener">www.baidu.com就是域名</a></p>
<p>DNS域名解析服务器，把域名解析为ip地址。保存的就是域名和ip地址的映射关系。</p>
<p>一级域名：baidu.com</p>
<p>二级域名：<a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a></p>
<p>三级域名：image.baidu.com</p>
<p>一个域名对应与一个ip地址，一个ip地址可以被多个域名绑定。</p>
<p>只需要买一个一级域名，后面的二级，三级域名你自己可以随便定义。</p>
<p>本地测试我们可以通过修改hosts配置文件来完成：</p>
<p>hosts文件的位置：C:\Windows\System32\drivers\etc</p>
<p>可以自己手动配置域名和ip的映射关系，如果hosts文件中配置了域名和ip的对应关系，不需要走DNS域名解析服务器。</p>
<p>因为拿到一个域名，首先是到hosts文件里面查找，没有才有去DNS域名解析器查找。</p>
<h2 id="2-nginx配置"><a href="#2-nginx配置" class="headerlink" title="2 nginx配置"></a>2 nginx配置</h2><p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528232837172-772759927.png" alt="img"></p>
<h2 id="3-测试"><a href="#3-测试" class="headerlink" title="3 测试"></a>3 测试</h2><p>1 修改本地hosts配置文件</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528233243735-537226043.png" alt="img"></p>
<p>2 复制html目录，分别改名为html-taobao和html-baidu</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528233425639-1929848567.png" alt="img"></p>
<p>3 分别修改html-baidu和html-taobao里面的index.html文件，方便区分</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528233638275-1668361848.png" alt="img"></p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180528233727028-1216322786.png" alt="img"></p>
<p>4 刷新配置文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@admin sbin]# .&#x2F;nginx -s reload</span><br></pre></td></tr></table></figure>

<p>5 然后使用浏览器分别访问：<a href="http://www.taobao.com" target="_blank" rel="noopener">www.taobao.com</a> 和 <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a></p>
<h1 id="13-正向代理"><a href="#13-正向代理" class="headerlink" title="13 正向代理"></a>13 正向代理</h1><p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180529000121513-942126145.png" alt="img"></p>
<h1 id="14-反向代理"><a href="#14-反向代理" class="headerlink" title="14 反向代理"></a>14 反向代理</h1><p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180529000622924-995860976.png" alt="img"></p>
<p>反向代理服务器决定那台服务器提供服务</p>
<h1 id="15-nginx实现反向代理"><a href="#15-nginx实现反向代理" class="headerlink" title="15 nginx实现反向代理"></a>15 nginx实现反向代理</h1><p>两个域名指向同一台nginx服务器，用户访问不同的域名显示不同的网页内容。</p>
<p>两个域名是<a href="http://www.baidu.com和www.taobao.com" target="_blank" rel="noopener">www.baidu.com和www.taobao.com</a></p>
<p>nginx代理服务器使用虚拟机192.168.204.131</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180529001151869-999884385.png" alt="img"></p>
<p>第一步：安装两个tomcat，分别运行在8080和8081端口。</p>
<p>第二步：启动两个tomcat。</p>
<p>第三步：反向代理服务器的配置</p>
<p> <img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180529001600606-1806158722.png" alt="img"></p>
<p>第四步：nginx重新加载配置文件</p>
<p>第五步：配置域名</p>
<p>在hosts文件中添加域名和ip的映射关系</p>
<p>192.168.204.131 <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a></p>
<p>192.168.204.131 <a href="http://www.taobao.com" target="_blank" rel="noopener">www.taobao.com</a></p>
<h1 id="16-负载均衡"><a href="#16-负载均衡" class="headerlink" title="16 负载均衡"></a>16 负载均衡</h1><p>如果一个服务由多个服务器提供，需要把负载分配到不同的服务器处理，需要负载均衡。</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180529002643025-1569805563.png" alt="img"></p>
<p>可以根据服务器的实际情况调整服务器权重。权重越高分配的请求越多，权重越低，请求越少。默认是都是1</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201805/1320077-20180529002741304-1542056839.png" alt="img"></p>
<h1 id="17-设置nginx开机自启动（centos6-5）"><a href="#17-设置nginx开机自启动（centos6-5）" class="headerlink" title="17 设置nginx开机自启动（centos6.5）"></a>17 设置nginx开机自启动（centos6.5）</h1><p>每次启动nginx服务都需要到安装目录下的/sbin下面，感觉挺麻烦的。</p>
<p>下面介绍一下如何在Linux(CentOS)系统上，设置nginx开机自启动。</p>
<h2 id="1-用脚本管理nginx服务"><a href="#1-用脚本管理nginx服务" class="headerlink" title="1 用脚本管理nginx服务"></a>1 用脚本管理nginx服务</h2><p><strong>第一步：在/etc/init.d/目录下创建nginx文件，命令如下：</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># touch &#x2F;etc&#x2F;init.d&#x2F;nginx</span><br></pre></td></tr></table></figure>

<p><strong>第二步：在创建的nginx文件中加入下面的内容</strong></p>
<p>首先执行命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># vim &#x2F;etc&#x2F;init.d&#x2F;nginx</span><br></pre></td></tr></table></figure>

<p>然后加下面的内容复制到nginx配置文件中</p>
<p><a href="javascript:void(0);"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;sh</span><br><span class="line">#</span><br><span class="line"># nginx - this script starts and stops the nginx daemon</span><br><span class="line">#</span><br><span class="line"># chkconfig:   - 85 15</span><br><span class="line"># description:  NGINX is an HTTP(S) server, HTTP(S) reverse \</span><br><span class="line">#               proxy and IMAP&#x2F;POP3 proxy server</span><br><span class="line"># processname: nginx</span><br><span class="line"># config:      &#x2F;etc&#x2F;nginx&#x2F;nginx.conf</span><br><span class="line"># config:      &#x2F;etc&#x2F;sysconfig&#x2F;nginx</span><br><span class="line"># pidfile:     &#x2F;var&#x2F;run&#x2F;nginx.pid</span><br><span class="line"># Source function library.</span><br><span class="line">. &#x2F;etc&#x2F;rc.d&#x2F;init.d&#x2F;functions</span><br><span class="line"># Source networking configuration.</span><br><span class="line">. &#x2F;etc&#x2F;sysconfig&#x2F;network</span><br><span class="line"># Check that networking is up.</span><br><span class="line">[ &quot;$NETWORKING&quot; &#x3D; &quot;no&quot; ] &amp;&amp; exit 0</span><br><span class="line">nginx&#x3D;&quot;&#x2F;usr&#x2F;sbin&#x2F;nginx&quot;</span><br><span class="line">prog&#x3D;$(basename $nginx)</span><br><span class="line">NGINX_CONF_FILE&#x3D;&quot;&#x2F;etc&#x2F;nginx&#x2F;nginx.conf&quot;</span><br><span class="line">[ -f &#x2F;etc&#x2F;sysconfig&#x2F;nginx ] &amp;&amp; . &#x2F;etc&#x2F;sysconfig&#x2F;nginx</span><br><span class="line">lockfile&#x3D;&#x2F;var&#x2F;lock&#x2F;subsys&#x2F;nginx</span><br><span class="line">make_dirs() &#123;</span><br><span class="line">   # make required directories</span><br><span class="line">   user&#x3D;&#96;$nginx -V 2&gt;&amp;1 | grep &quot;configure arguments:&quot; | sed &#39;s&#x2F;[^*]*--user&#x3D;\([^ ]*\).*&#x2F;\1&#x2F;g&#39; -&#96;</span><br><span class="line">   if [ -z &quot;&#96;grep $user &#x2F;etc&#x2F;passwd&#96;&quot; ]; then</span><br><span class="line">       useradd -M -s &#x2F;bin&#x2F;nologin $user</span><br><span class="line">   fi</span><br><span class="line">   options&#x3D;&#96;$nginx -V 2&gt;&amp;1 | grep &#39;configure arguments:&#39;&#96;</span><br><span class="line">   for opt in $options; do</span><br><span class="line">       if [ &#96;echo $opt | grep &#39;.*-temp-path&#39;&#96; ]; then</span><br><span class="line">           value&#x3D;&#96;echo $opt | cut -d &quot;&#x3D;&quot; -f 2&#96;</span><br><span class="line">           if [ ! -d &quot;$value&quot; ]; then</span><br><span class="line">               # echo &quot;creating&quot; $value</span><br><span class="line">               mkdir -p $value &amp;&amp; chown -R $user $value</span><br><span class="line">           fi</span><br><span class="line">       fi</span><br><span class="line">   done</span><br><span class="line">&#125;</span><br><span class="line">start() &#123;</span><br><span class="line">    [ -x $nginx ] || exit 5</span><br><span class="line">    [ -f $NGINX_CONF_FILE ] || exit 6</span><br><span class="line">    make_dirs</span><br><span class="line">    echo -n $&quot;Starting $prog: &quot;</span><br><span class="line">    daemon $nginx -c $NGINX_CONF_FILE</span><br><span class="line">    retval&#x3D;$?</span><br><span class="line">    echo</span><br><span class="line">    [ $retval -eq 0 ] &amp;&amp; touch $lockfile</span><br><span class="line">    return $retval</span><br><span class="line">&#125;</span><br><span class="line">stop() &#123;</span><br><span class="line">    echo -n $&quot;Stopping $prog: &quot;</span><br><span class="line">    killproc $prog -QUIT</span><br><span class="line">    retval&#x3D;$?</span><br><span class="line">    echo</span><br><span class="line">    [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile</span><br><span class="line">    return $retval</span><br><span class="line">&#125;</span><br><span class="line">restart() &#123;</span><br><span class="line">    configtest || return $?</span><br><span class="line">    stop</span><br><span class="line">    sleep 1</span><br><span class="line">    start</span><br><span class="line">&#125;</span><br><span class="line">reload() &#123;</span><br><span class="line">    configtest || return $?</span><br><span class="line">    echo -n $&quot;Reloading $prog: &quot;</span><br><span class="line">    killproc $nginx -HUP</span><br><span class="line">    RETVAL&#x3D;$?</span><br><span class="line">    echo</span><br><span class="line">&#125;</span><br><span class="line">force_reload() &#123;</span><br><span class="line">    restart</span><br><span class="line">&#125;</span><br><span class="line">configtest() &#123;</span><br><span class="line">  $nginx -t -c $NGINX_CONF_FILE</span><br><span class="line">&#125;</span><br><span class="line">rh_status() &#123;</span><br><span class="line">    status $prog</span><br><span class="line">&#125;</span><br><span class="line">rh_status_q() &#123;</span><br><span class="line">    rh_status &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1</span><br><span class="line">&#125;</span><br><span class="line">case &quot;$1&quot; in</span><br><span class="line">    start)</span><br><span class="line">        rh_status_q &amp;&amp; exit 0</span><br><span class="line">        $1</span><br><span class="line">        ;;</span><br><span class="line">    stop)</span><br><span class="line">        rh_status_q || exit 0</span><br><span class="line">        $1</span><br><span class="line">        ;;</span><br><span class="line">    restart|configtest)</span><br><span class="line">        $1</span><br><span class="line">        ;;</span><br><span class="line">    reload)</span><br><span class="line">        rh_status_q || exit 7</span><br><span class="line">        $1</span><br><span class="line">        ;;</span><br><span class="line">    force-reload)</span><br><span class="line">        force_reload</span><br><span class="line">        ;;</span><br><span class="line">    status)</span><br><span class="line">        rh_status</span><br><span class="line">        ;;</span><br><span class="line">    condrestart|try-restart)</span><br><span class="line">        rh_status_q || exit 0</span><br><span class="line">            ;;</span><br><span class="line">    *)</span><br><span class="line">        echo $&quot;Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest&#125;&quot;</span><br><span class="line">        exit 2</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>

<p><a href="javascript:void(0);"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p>上面的脚本文件并不是自己写的，是nginx官方提供的。</p>
<p>地址：<a href="http://wiki.nginx.org/RedHatNginxInitScript" target="_blank" rel="noopener">http://wiki.nginx.org/RedHatNginxInitScript</a></p>
<p>注意：如果是自定义安装的nginx,修改根据实际情况修改安装路和配置文件。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nginx&#x3D;&quot;&#x2F;usr&#x2F;sbin&#x2F;nginx&quot; 修改成你的nginx执行程序的路径。比如我的是nginx&#x3D;&quot;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx&quot;</span><br><span class="line">NGINX_CONF_FILE&#x3D;&quot;&#x2F;etc&#x2F;nginx&#x2F;nginx.conf&quot; 修改成你的配置文件的路径</span><br><span class="line">例如：NGINX_CONF_FILE&#x3D;&quot;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;nginx.conf</span><br></pre></td></tr></table></figure>

<p>修改完成后保存脚本文件，wq 保存并退出</p>
<p><strong>第三步：设置nginx文件的权限</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># chmod a+x &#x2F;etc&#x2F;init.d&#x2F;nginx</span><br></pre></td></tr></table></figure>

<p>解释：a+x==&gt;all user can execute 所有用户可执行）的意思</p>
<p><strong>第四步：管理脚本</strong></p>
<p>到这里，我们就可以使用nginx脚本对服务进行管理了</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># &#x2F;etc&#x2F;init.d&#x2F;nginx start      启动服务</span><br><span class="line"># &#x2F;etc&#x2F;init.d&#x2F;nginx stop       停止服务  # &#x2F;etc&#x2F;init.d&#x2F;nginx restart    重启服务</span><br><span class="line"># &#x2F;etc&#x2F;init.d&#x2F;nginx status     查看服务的状态# &#x2F;etc&#x2F;init.d&#x2F;nginx reload     刷新配置文件</span><br></pre></td></tr></table></figure>

<h2 id="2-使用chkconfig管理"><a href="#2-使用chkconfig管理" class="headerlink" title="2 使用chkconfig管理"></a>2 使用chkconfig管理</h2><p>上面的方法完成了用脚本管理nginx服务的功能，但是还是不太方便，比如要设置nginx开机启动等。</p>
<p>这个时候我们可以使用chkconfig来进行管理。</p>
<p><strong>第一步：将nginx服务加入chkconfig管理列表</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># chkconfig --add &#x2F;etc&#x2F;init.d&#x2F;nginx</span><br></pre></td></tr></table></figure>

<p><strong>第二步：使用service管理服务</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># service nginx start    启动服务</span><br><span class="line"># service nginx stop     停止服务# service nginx restart  重启服务# service nginx status   查询服务的状态# service nginx relaod   刷新配置文</span><br></pre></td></tr></table></figure>

<p><strong>第三步：设置终端模式开机启动</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># chkconfig nginx on</span><br></pre></td></tr></table></figure>



<h1 id="17-设置nginx开机自启动（centos7-4）"><a href="#17-设置nginx开机自启动（centos7-4）" class="headerlink" title="17 设置nginx开机自启动（centos7.4）"></a>17 设置nginx开机自启动（centos7.4）</h1><p> <strong>第一步：进入到/lib/systemd/system/目录</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@iz2z init.d]# cd &#x2F;lib&#x2F;systemd&#x2F;system&#x2F;</span><br></pre></td></tr></table></figure>

<p><strong>第二步：创建nginx.service文件，并编辑</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># vim nginx.service</span><br></pre></td></tr></table></figure>

<p>内如如下：</p>
<p><a href="javascript:void(0);"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description&#x3D;nginx service</span><br><span class="line">After&#x3D;network.target </span><br><span class="line">   </span><br><span class="line">[Service] </span><br><span class="line">Type&#x3D;forking </span><br><span class="line">ExecStart&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx</span><br><span class="line">ExecReload&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -s reload</span><br><span class="line">ExecStop&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -s quit</span><br><span class="line">PrivateTmp&#x3D;true </span><br><span class="line">   </span><br><span class="line">[Install] </span><br><span class="line">WantedBy&#x3D;multi-user.target</span><br></pre></td></tr></table></figure>

<p><a href="javascript:void(0);"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p>Description:描述服务<br>After:描述服务类别<br>[Service]服务运行参数的设置<br>Type=forking是后台运行的形式<br>ExecStart为服务的具体运行命令<br>ExecReload为重启命令<br>ExecStop为停止命令<br>PrivateTmp=True表示给服务分配独立的临时空间<br>注意：[Service]的启动、重启、停止命令全部要求使用绝对路径<br>[Install]运行级别下服务安装的相关设置，可设置为多用户，即系统运行级别为3</p>
<p>保存退出。</p>
<p><strong>第三步：加入开机自启动</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># systemctl enable nginx</span><br></pre></td></tr></table></figure>

<p>如果不想开机自启动了，可以使用下面的命令取消开机自启动</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># systemctl disable nginx</span><br></pre></td></tr></table></figure>

<p><strong>第四步：服务的启动/停止/刷新配置文件/查看状态</strong></p>
<p><a href="javascript:void(0);"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># systemctl start nginx.service　         启动nginx服务</span><br><span class="line"># systemctl stop nginx.service　          停止服务</span><br><span class="line"># systemctl restart nginx.service　       重新启动服务</span><br><span class="line"># systemctl list-units --type&#x3D;service     查看所有已启动的服务</span><br><span class="line"># systemctl status nginx.service          查看服务当前状态</span><br><span class="line"># systemctl enable nginx.service          设置开机自启动</span><br><span class="line"># systemctl disable nginx.service         停止开机自启动</span><br></pre></td></tr></table></figure>

<p><a href="javascript:void(0);"><img src="https://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<h2 id="一个常见的错误"><a href="#一个常见的错误" class="headerlink" title="一个常见的错误"></a><strong>一个常见的错误</strong></h2><h3 id="Warning-nginx-service-changed-on-disk-Run-‘systemctl-daemon-reload’-to-reload-units"><a href="#Warning-nginx-service-changed-on-disk-Run-‘systemctl-daemon-reload’-to-reload-units" class="headerlink" title="Warning: nginx.service changed on disk. Run ‘systemctl daemon-reload’ to reload units."></a>Warning: nginx.service changed on disk. Run ‘systemctl daemon-reload’ to reload units.</h3><p> 直接按照提示执行命令systemctl daemon-reload 即可。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># systemctl daemon-reload</span><br></pre></td></tr></table></figure>



<h1 id="18-重启系统，再次启动nginx报错"><a href="#18-重启系统，再次启动nginx报错" class="headerlink" title="18 重启系统，再次启动nginx报错"></a>18 重启系统，再次启动nginx报错</h1><h2 id="1-故障现场"><a href="#1-故障现场" class="headerlink" title="1 故障现场"></a>1 故障现场</h2><p>之前在虚拟机centos6.5上面设置自启动之后，重新启动系统可以正常启动，也不会出错。</p>
<p>centos6.5的自启动设置见16部分知识点。</p>
<p>但是在centos7.4(阿里云上面），参照第17部分配置好了自启动。重启系统发现nginx并没有自启动</p>
<p>使用命名systemctl status nginx查看了一下状态，内容如下：</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201806/1320077-20180603235731837-1149240490.png" alt="img"></p>
<p>然后我直接进入/usr/local/nginx/sbin目录下面，执行./nginx，出现了下面的错误提示：</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201806/1320077-20180603235854971-2001750680.png" alt="img"></p>
<p>从这两个提示信息，可以大概看出告诉我们的就是找不到/var/run/nginx/目录下面的nginx.pid文件。</p>
<h2 id="2-故障解决"><a href="#2-故障解决" class="headerlink" title="2 故障解决"></a>2 故障解决</h2><p><strong>第一步：进入 cd /usr/local/nginx/conf/ 目录，编辑配置文件nginx.conf ；</strong></p>
<p>在配置文件中找到：#pid    logs/nginx.pid;</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201806/1320077-20180604000215412-935975488.png" alt="img"></p>
<p>将其修改为：去掉注释，修改成自己的路径</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201806/1320077-20180604000522605-1193262105.png" alt="img"></p>
<p>修改完成保存退出</p>
<p><strong>第二步：创建目录/var/run/nginx/</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># mkdir &#x2F;var&#x2F;run&#x2F;nginx -p</span><br></pre></td></tr></table></figure>

<p><strong>第三步：启动nginx服务</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx</span><br></pre></td></tr></table></figure>

<p>可以查看一下是否成功启动了</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201806/1320077-20180604001021288-75578496.png" alt="img"></p>
<h2 id="3-故障重现"><a href="#3-故障重现" class="headerlink" title="3 故障重现"></a>3 故障重现</h2><p><strong>[emerg] open() “/var/run/nginx/nginx.pid” failed (2: No such file or directory)处理</strong></p>
<p>测试发现，只要执行reboot命令重启，var/run/nginx，nginx这个文件夹都会被删除，</p>
<p>搞得每一次都要去建立nginx这个文件夹，简直麻烦到了极点，实在受不了。下面</p>
<p>继续来解决这个问题。</p>
<p><strong>第一步：进入 cd /usr/local/nginx/conf/ 目录，编辑配置文件nginx.conf ；</strong></p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201806/1320077-20180604004515961-636067355.png" alt="img"></p>
<p><strong>第二步：在/usr/local/nginx目录下建立logs文件夹</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># mkdir &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;logs</span><br></pre></td></tr></table></figure>

<p><strong><img src="https://images2018.cnblogs.com/blog/1320077/201806/1320077-20180604005704151-2060063432.png" alt="img"></strong></p>
<p><strong>第三步：把/var/run/nginx/目录下的nginx.pid这个文件拷贝到第二步创建的logs文件夹里面。</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cp nginx.pid &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;logs&#x2F;</span><br></pre></td></tr></table></figure>

<p> <img src="https://images2018.cnblogs.com/blog/1320077/201806/1320077-20180604005724309-1632561610.png" alt="img"></p>
<p><strong>第四步：把logs这个文件夹在conf下也拷贝一份</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cp -r logs conf</span><br></pre></td></tr></table></figure>

<p><img src="https://images2018.cnblogs.com/blog/1320077/201806/1320077-20180604005846851-1054721549.png" alt="img"></p>
<p><strong>第五步：修改权限/usr/local/nginx/logs/目录下面的nginx.pid文件的权限。</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@iz2logs]# chmod 755 nginx.pid</span><br></pre></td></tr></table></figure>

<p><img src="https://images2018.cnblogs.com/blog/1320077/201806/1320077-20180604010132048-1203053027.png" alt="img"></p>
<p><strong>第六步：重启reboot</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># reboot</span><br></pre></td></tr></table></figure>

<p><strong>第六步：启动nginx</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx</span><br></pre></td></tr></table></figure>

<p><img src="https://images2018.cnblogs.com/blog/1320077/201806/1320077-20180604010643083-893375042.png" alt="img"></p>
<p>这次是终于成功解决了，一边安装一边解决问题，到这里nginx总是算是可以自启动了，并且也不会重启后找不到nginx.pid文件。真的太不容易了。</p>
<p><strong>解决的原理：就是让它去另外一个地方找nginx.pid文件，</strong></p>
<p><strong>因为/var/run/nginx/nginx.pid这个文件总是重启就删除了</strong>。</p>
<h2 id="简单解决方案"><a href="#简单解决方案" class="headerlink" title="简单解决方案"></a>简单解决方案</h2><p>上面的过程有点繁琐了，实际可以直接按照下面的这个简单方法解决</p>
<p>修改nginx.conf文件如下：</p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201806/1320077-20180604012457087-1758425381.png" alt="img"></p>
<p>在/usr/local/nginx/目录下创建一个logs目录。</p>
<p>然后启动就可以了，并且重启也不会被删除。</p>
<p>这样下面的日志文件的配置也可以简化为去掉# error_log logs/error.log info; 前面的“#”就可以了</p>
<p>error_log logs/error.log info;</p>
<h1 id="19-配置日志文件的位置"><a href="#19-配置日志文件的位置" class="headerlink" title="19 配置日志文件的位置"></a>19 配置日志文件的位置</h1><p><strong>第一步：进入 cd /usr/local/nginx/conf/ 目录，编辑配置文件nginx.conf ；</strong></p>
<p><img src="https://images2018.cnblogs.com/blog/1320077/201806/1320077-20180604001806779-1643312454.png" alt="img"></p>
<p><strong>第二步：保证肯定有这个路径，可以直接创建一下这个配置的目录</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># mkdir -p &#x2F;var&#x2F;log&#x2F;nginx&#x2F;</span><br></pre></td></tr></table></figure>

<p><strong>第三步：刷新配置文件</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -s reload</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu安装VMware Tools</title>
    <url>/2020/08/03/ubuntu%E5%AE%89%E8%A3%85VMware-Tools/</url>
    <content><![CDATA[<p>VMware的安装非常简单，就不详细阐述了，这里主要是记录一个罕见的问题。</p>
<a id="more"></a>

<blockquote>
<p>报错：在解压wmware tools时ubuntu报出没有足够的空间提取的错误</p>
</blockquote>
<p>这里需要通过归档管理器打开文件<br><img src="/images/2020080301.png" alt="解压"><br>然后在解压安装即可<br><img src="/images/2020080302.png" alt="解压"></p>
<p>解压完成之后即可运行安装文件安装wmware tools</p>
]]></content>
      <categories>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>多态是编译时行为还是运行时行为？</title>
    <url>/2020/08/01/%E5%A4%9A%E6%80%81%E6%98%AF%E7%BC%96%E8%AF%91%E6%97%B6%E8%A1%8C%E4%B8%BA%E8%BF%98%E6%98%AF%E8%BF%90%E8%A1%8C%E6%97%B6%E8%A1%8C%E4%B8%BA%EF%BC%9F/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>浅析equals()和hashcode()方法</title>
    <url>/2020/08/06/%E6%B5%85%E6%9E%90equals-%E5%92%8Chashcode-%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>需要注意的是当equals()方法被override时，hashCode()也要被override。按照一般hashCode()方法的实现来说，相等的对象，它们的hash code一定相等。</p>
]]></content>
  </entry>
  <entry>
    <title>解决Docker上安装RabbitMQ后Web管理页面打不开的问题</title>
    <url>/2020/07/27/%E8%A7%A3%E5%86%B3Docker%E4%B8%8A%E5%AE%89%E8%A3%85RabbitMQ%E5%90%8EWeb%E7%AE%A1%E7%90%86%E9%A1%B5%E9%9D%A2%E6%89%93%E4%B8%8D%E5%BC%80%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>首先确保RabbitMQ的端口等配置正确，进入RabbitMQ中，开启一项配置。</p>
<a id="more"></a>

<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>1.开启RabbitMQ  　　</p>
<p><code>docker run -itd --name myrabbitmq -p 15672:15672 -p 5672:5672 rabbitmq</code></p>
<p>2.进入RabbitMQ　　</p>
<p><code>docker exec -it myrabbitmq /bin/bash</code></p>
<p>3.开启　</p>
<p><code>rabbitmq-plugins enable rabbitmq_management</code></p>
]]></content>
      <categories>
        <category>RabbitMQ</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title>解决idea不显示maven工具栏的问题</title>
    <url>/2020/08/11/%E8%A7%A3%E5%86%B3idea%E4%B8%8D%E6%98%BE%E7%A4%BAmaven%E5%B7%A5%E5%85%B7%E6%A0%8F%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>启动idea发现maven并没有显示，hhh,莫名其妙的问题？？？</p>
<h3 id="解决方法："><a href="#解决方法：" class="headerlink" title="解决方法："></a>解决方法：</h3><p><img src="/images/2020081101.png" alt="报错问题"></p>
]]></content>
      <categories>
        <category>idea小技巧</category>
      </categories>
      <tags>
        <tag>idea小技巧</tag>
      </tags>
  </entry>
</search>
